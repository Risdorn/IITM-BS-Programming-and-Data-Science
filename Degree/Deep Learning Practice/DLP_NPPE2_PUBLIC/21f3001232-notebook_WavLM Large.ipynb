{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":95302,"databundleVersionId":11325230,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:27:04.054608Z","iopub.execute_input":"2025-03-10T13:27:04.054895Z","iopub.status.idle":"2025-03-10T13:27:04.360509Z","shell.execute_reply.started":"2025-03-10T13:27:04.054876Z","shell.execute_reply":"2025-03-10T13:27:04.359835Z"},"id":"CNubN5_6UoRm","outputId":"0effea96-3e0f-4afb-ea0a-b9020164d769"},"outputs":[{"name":"stdout","text":"/kaggle/input/indic-tts-deepfake-challenge/sample.csv\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"id":"Zg-4AjamWdgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","\n","dataset = load_dataset(\"SherryT997/IndicTTS-Deepfake-Challenge-Data\")\n","\n","train_data = dataset[\"train\"]\n","test_data = dataset[\"test\"]\n","\n","print(train_data.features)\n","print(train_data[0])"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:22:36.963848Z","iopub.execute_input":"2025-03-10T10:22:36.964266Z","iopub.status.idle":"2025-03-10T10:27:14.984565Z","shell.execute_reply.started":"2025-03-10T10:22:36.964217Z","shell.execute_reply":"2025-03-10T10:27:14.983657Z"},"colab":{"referenced_widgets":["f9ca753c21064af9bd0b83dc978eef53","fc1ae55d2e814bdaa90373e10b02d8b0","2f9e0e06414a4356bef9d8776cbd6b8b","7f88735e0b6941ff8a8f1e485415ad1a","b5fb22735eed44449e5652fc05bdd0d1","724610a161e84ff4a2ecee7130edb038","ae264e8654004ac199c8dd185dc685e6","43f13c68ebc54c66a03cc5742b0e8590","c6cc41d766c042f6a1f55a0a614331d1","d8ae677d3f3d40328eb6c3a693c5f875","51cb4f8d7bc3426992202566a2153499","5859d59bcf0a4c6db07e870461c6c0b1","c47690925c7048458f5cc60a600a33d0","e8a46889e5bf4b9d845e97f63a192c3b","4110ce0cf15e4789810cab8167be6f0c","109fbc4fd3c14818891f2ead55238918","6f767690169943758af452223aa1c6a7","0d6ea7ea3dc348c3af03f49804fbb68c","07784134b3c64e829b9b9fbf9b475591","61e35d9684b74b219a33d9cbb52cf7c9","6308ea22f8e54b14aa58a18538733665","808b1b3ec12442acab2116a8cb8bd15d","ae8124b76bec4162916d3877a201fb5b","7e0d1d971df84073b35625fdf11e7dff","0fa6f68388854764aa5e4d1ae9ea3cc7","5ab0af9319464d41a2499de29f5b1874","803f2b0f0eaa461189e2a3116f6a79ab","05cc87a9338f49b38c6d63d9885cbb87","e5b03618847d4470b435e8a210dcfc54","7c87b9254ae84661b360ac4eb5df3374","21b3076fc792420298458550eef5ba55","8449ac8a06224a1ea43565b9c32c9b16","86b6caf512dc4a71a979da495317ff87","71407abcaa274be7843c68ca4fe6f6d7","463c1ee7353547d2837c29a5c5bfafe8","5cb6eb92362a41a0997cebd7efc60d4e","9a8f8bed78de46a39e7e689ae259b18a","d39d990080514ecc86c51a2a16f4630f","db3b595732b34c27b7f498518daec582","11adcc40caac4525b0421b16545303be","7b4fc111c012415cbff261d855c3f37c","4ef26d0ad1104eef9e018897c325222a","23880c64a0bc4f01a811ad8abaee2cf8","c998d29f8e164f4fbac749794c458815","de34126d06754b3eb2fc4facab28353c","261e2253beec404e89175b67d1b72375"]},"id":"H4gtRLZRUoRq","outputId":"71f99cf6-3438-446b-955c-053940283b48"},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ca753c21064af9bd0b83dc978eef53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc1ae55d2e814bdaa90373e10b02d8b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f9e0e06414a4356bef9d8776cbd6b8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/35 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f88735e0b6941ff8a8f1e485415ad1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00035.parquet:   0%|          | 0.00/453M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5fb22735eed44449e5652fc05bdd0d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00035.parquet:   0%|          | 0.00/461M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"724610a161e84ff4a2ecee7130edb038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00035.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae264e8654004ac199c8dd185dc685e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00035.parquet:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f13c68ebc54c66a03cc5742b0e8590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00035.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6cc41d766c042f6a1f55a0a614331d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00035.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8ae677d3f3d40328eb6c3a693c5f875"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00035.parquet:   0%|          | 0.00/447M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51cb4f8d7bc3426992202566a2153499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00035.parquet:   0%|          | 0.00/516M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5859d59bcf0a4c6db07e870461c6c0b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00035.parquet:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c47690925c7048458f5cc60a600a33d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00035.parquet:   0%|          | 0.00/521M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8a46889e5bf4b9d845e97f63a192c3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00035.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4110ce0cf15e4789810cab8167be6f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00035.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109fbc4fd3c14818891f2ead55238918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00035.parquet:   0%|          | 0.00/414M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f767690169943758af452223aa1c6a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00035.parquet:   0%|          | 0.00/473M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d6ea7ea3dc348c3af03f49804fbb68c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00035.parquet:   0%|          | 0.00/481M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07784134b3c64e829b9b9fbf9b475591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00035.parquet:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61e35d9684b74b219a33d9cbb52cf7c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00035.parquet:   0%|          | 0.00/532M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6308ea22f8e54b14aa58a18538733665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00035.parquet:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"808b1b3ec12442acab2116a8cb8bd15d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00035.parquet:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae8124b76bec4162916d3877a201fb5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00035.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e0d1d971df84073b35625fdf11e7dff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00035.parquet:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fa6f68388854764aa5e4d1ae9ea3cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00035.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab0af9319464d41a2499de29f5b1874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00035.parquet:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803f2b0f0eaa461189e2a3116f6a79ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00035.parquet:   0%|          | 0.00/599M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05cc87a9338f49b38c6d63d9885cbb87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00035.parquet:   0%|          | 0.00/576M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b03618847d4470b435e8a210dcfc54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00035.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c87b9254ae84661b360ac4eb5df3374"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00035.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b3076fc792420298458550eef5ba55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00035.parquet:   0%|          | 0.00/421M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8449ac8a06224a1ea43565b9c32c9b16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00035.parquet:   0%|          | 0.00/382M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86b6caf512dc4a71a979da495317ff87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00035.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71407abcaa274be7843c68ca4fe6f6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00030-of-00035.parquet:   0%|          | 0.00/282M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"463c1ee7353547d2837c29a5c5bfafe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00031-of-00035.parquet:   0%|          | 0.00/688M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cb6eb92362a41a0997cebd7efc60d4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00032-of-00035.parquet:   0%|          | 0.00/613M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a8f8bed78de46a39e7e689ae259b18a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00033-of-00035.parquet:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d39d990080514ecc86c51a2a16f4630f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00034-of-00035.parquet:   0%|          | 0.00/424M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3b595732b34c27b7f498518daec582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00004.parquet:   0%|          | 0.00/356M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11adcc40caac4525b0421b16545303be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00001-of-00004.parquet:   0%|          | 0.00/364M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4fc111c012415cbff261d855c3f37c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00002-of-00004.parquet:   0%|          | 0.00/410M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef26d0ad1104eef9e018897c325222a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00003-of-00004.parquet:   0%|          | 0.00/291M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23880c64a0bc4f01a811ad8abaee2cf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/31102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c998d29f8e164f4fbac749794c458815"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2635 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de34126d06754b3eb2fc4facab28353c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261e2253beec404e89175b67d1b72375"}},"metadata":{}},{"name":"stdout","text":"{'text': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'language': Value(dtype='string', id=None), 'is_tts': Value(dtype='int64', id=None), 'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n{'text': 'বিত্তীয় সময়সীমা মানি চলাত বাৰে বাৰে বিফল হোৱাৰ বাবে মই বৰ হতাশ হৈছোঁ।', 'id': 'ASM_F_ANGER_00342', 'language': 'Assamese', 'is_tts': 1, 'audio': {'path': 'ASM_F_ANGER_00342.wav', 'array': array([-0.00297868, -0.00474697, -0.00408163, ..., -0.00600238,\n       -0.00075703,  0.00277057]), 'sampling_rate': 16000}}\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n","from transformers import Trainer, TrainingArguments, AutoProcessor, AutoFeatureExtractor, AutoModelForAudioClassification\n","from datasets import load_dataset, Audio"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:27:14.985682Z","iopub.execute_input":"2025-03-10T10:27:14.986384Z","iopub.status.idle":"2025-03-10T10:27:36.498539Z","shell.execute_reply.started":"2025-03-10T10:27:14.986360Z","shell.execute_reply":"2025-03-10T10:27:36.497577Z"},"colab":{"referenced_widgets":["adc11657a3d84165ae8035312f0785f9"]},"id":"CRPYB--KUoRt","outputId":"65774ba8-acda-4a35-933a-74d0e618aa43"},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adc11657a3d84165ae8035312f0785f9"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["model_id = \"microsoft/wavlm-large\"\n","feature_extractor = AutoFeatureExtractor.from_pretrained(model_id, do_normalize=True, return_attention_mask=True)\n","model = AutoModelForAudioClassification.from_pretrained(model_id, num_labels=2)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:27:36.504198Z","iopub.execute_input":"2025-03-10T10:27:36.504426Z","iopub.status.idle":"2025-03-10T10:27:43.463679Z","shell.execute_reply.started":"2025-03-10T10:27:36.504405Z","shell.execute_reply":"2025-03-10T10:27:43.462574Z"},"colab":{"referenced_widgets":["13c0522f05494ad4b0c3552957e455ea","dc84c50af47c49d38a0cc23342fcb0d3","c552032824de45a581867da58ea8fb66"]},"id":"fZupL9q5UoRu","outputId":"208b5525-3802-4c61-a5f9-1a0ee15a553c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c0522f05494ad4b0c3552957e455ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc84c50af47c49d38a0cc23342fcb0d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c552032824de45a581867da58ea8fb66"}},"metadata":{}},{"name":"stderr","text":"Some weights of WavLMForSequenceClassification were not initialized from the model checkpoint at microsoft/wavlm-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:28:15.694767Z","iopub.execute_input":"2025-03-10T10:28:15.695090Z","iopub.status.idle":"2025-03-10T10:28:15.753081Z","shell.execute_reply.started":"2025-03-10T10:28:15.695065Z","shell.execute_reply":"2025-03-10T10:28:15.752070Z"},"id":"OZnDleyGUoRv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"trusted":true,"id":"TkaZXd2XUoRx"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def processing_audio(batch):\n","    audio = batch[\"audio\"][\"array\"]\n","    max_length = 16000\n","    if len(audio) < max_length:\n","        audio = np.pad(audio, (0, max_length - len(audio)), mode='constant')\n","    else:\n","        audio = audio[:max_length]\n","\n","    inputs = feature_extractor(audio, sampling_rate=16000, return_tensors=\"pt\",padding=True)\n","    batch[\"input_values\"] = inputs.input_values[0]\n","    batch[\"labels\"] = torch.tensor(batch[\"is_tts\"], dtype=torch.float)\n","\n","    return batch\n","\n","train_dataset = train_data.map(processing_audio, remove_columns=[\"audio\", \"text\", \"id\", \"language\", \"is_tts\"])"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:28:19.745758Z","iopub.execute_input":"2025-03-10T10:28:19.746062Z","iopub.status.idle":"2025-03-10T10:33:19.787398Z","shell.execute_reply.started":"2025-03-10T10:28:19.746036Z","shell.execute_reply":"2025-03-10T10:33:19.786404Z"},"colab":{"referenced_widgets":["b91e862d44594f1687a1af2ea25c3c9a"]},"id":"wtkMo9bGUoRx","outputId":"08b1dd72-bc5b-40e2-bb41-f77b5501a7ac"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/31102 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b91e862d44594f1687a1af2ea25c3c9a"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["dataset = train_dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:33:19.788631Z","iopub.execute_input":"2025-03-10T10:33:19.788944Z","iopub.status.idle":"2025-03-10T10:33:19.809258Z","shell.execute_reply.started":"2025-03-10T10:33:19.788921Z","shell.execute_reply":"2025-03-10T10:33:19.808425Z"},"id":"qnRguHONUoRy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:33:44.135203Z","iopub.execute_input":"2025-03-10T10:33:44.135565Z","iopub.status.idle":"2025-03-10T10:33:48.788574Z","shell.execute_reply.started":"2025-03-10T10:33:44.135536Z","shell.execute_reply":"2025-03-10T10:33:48.787561Z"},"scrolled":true,"id":"OHnNi49HUoRz","outputId":"2de6885e-fe0f-4947-c600-192f19c40d20"},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["from transformers import DataCollatorWithPadding\n","from evaluate import load\n","from dataclasses import dataclass\n","from typing import List, Dict, Union\n","\n","@dataclass\n","\n","\n","class DataCollatorWithPadding:\n","\n","    processor: feature_extractor  # Use full processor for consistency\n","    padding: Union[bool, str] = True\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # Extract input features (waveforms)\n","        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n","\n","        # Apply padding using processor\n","        batch = self.processor.pad(\n","            input_features,\n","            padding=self.padding,\n","            return_tensors=\"pt\",\n","        )\n","\n","        # Convert labels to tensor\n","        batch[\"labels\"] = torch.tensor([feature[\"labels\"] for feature in features], dtype=torch.long)\n","\n","        return batch\n","\n","data_collator = DataCollatorWithPadding(feature_extractor, padding=True)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:33:53.740065Z","iopub.execute_input":"2025-03-10T10:33:53.740403Z","iopub.status.idle":"2025-03-10T10:33:53.908380Z","shell.execute_reply.started":"2025-03-10T10:33:53.740374Z","shell.execute_reply":"2025-03-10T10:33:53.907701Z"},"id":"Jt9rNH03UoR0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","from evaluate import load\n","from scipy.special import softmax\n","\n","accuracy_metric = load(\"accuracy\")\n","precision_metric = load(\"precision\")\n","recall_metric = load(\"recall\")\n","f1_metric = load(\"f1\")\n","roc_auc_metric = load(\"roc_auc\")\n","\n","\n","def compute_metrics(eval_pred):\n","    pred_logits = eval_pred.predictions\n","    pred_probs = softmax(pred_logits, axis = -1)[:,1]\n","    labels = eval_pred.label_ids\n","\n","    accuracy = accuracy_metric.compute(predictions=pred_probs.round(), references = labels)[\"accuracy\"]\n","    f1 = f1_metric.compute(predictions=pred_probs.round(), references = labels, average=\"binary\")[\"f1\"]\n","    roc_auc = roc_auc_metric.compute(prediction_scores = pred_probs, references = labels)[\"roc_auc\"]\n","\n","    return { \"accuracy\": accuracy,\"f1\": f1, \"roc_auc\": roc_auc}"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:33:59.043169Z","iopub.execute_input":"2025-03-10T10:33:59.043488Z","iopub.status.idle":"2025-03-10T10:34:02.334332Z","shell.execute_reply.started":"2025-03-10T10:33:59.043466Z","shell.execute_reply":"2025-03-10T10:34:02.333705Z"},"colab":{"referenced_widgets":["d30021051a9f4601a7e1609e98d284b3","f703118924be416fadbf36fa0b143249","f0f3ba2d68674deeb8d4279d8504086b","7ee3f445127b42bb90bb0b092cae082a","6d06fe15434e4e288ec3a0c6c485d9ab"]},"id":"sAl5tmQjUoR1","outputId":"4a2ffdfe-2863-4fb0-fcfa-6f32e9e3683f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d30021051a9f4601a7e1609e98d284b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f703118924be416fadbf36fa0b143249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f3ba2d68674deeb8d4279d8504086b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee3f445127b42bb90bb0b092cae082a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d06fe15434e4e288ec3a0c6c485d9ab"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["model.to(\"cuda\")\n","model.freeze_feature_encoder()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:34:07.798032Z","iopub.execute_input":"2025-03-10T10:34:07.798403Z","iopub.status.idle":"2025-03-10T10:34:13.407784Z","shell.execute_reply.started":"2025-03-10T10:34:07.798358Z","shell.execute_reply":"2025-03-10T10:34:13.407108Z"},"id":"U0eaFdVhUoR3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"data_classify\",\n","    group_by_length=True,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    evaluation_strategy=\"steps\",\n","    num_train_epochs=3,\n","    fp16=True,\n","    gradient_checkpointing=True,\n","    save_steps=1000,\n","    eval_steps=500,\n","    logging_steps=500,\n","    learning_rate=1e-4,\n","    weight_decay=0.005,\n","    warmup_steps=1000,\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n","    save_strategy=\"steps\",\n","    report_to=\"none\"\n",")\n","\n","# Define trainer\n","trainer = Trainer(\n","    model=model,\n","    data_collator=data_collator,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    tokenizer=feature_extractor,\n",")\n","trainer.train()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:34:18.643425Z","iopub.execute_input":"2025-03-10T10:34:18.643715Z","execution_failed":"2025-03-10T13:24:13.226Z"},"scrolled":true,"id":"BRFHKDaAUoR4","outputId":"2c01a6c0-c796-4865-b049-32babe5a2c90"},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-14-7e8f3051d7f6>:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12733' max='20994' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12733/20994 1:52:28 < 1:12:58, 1.89 it/s, Epoch 3.64/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.596900</td>\n      <td>0.409226</td>\n      <td>0.838637</td>\n      <td>0.815169</td>\n      <td>0.966430</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.305200</td>\n      <td>0.492080</td>\n      <td>0.849245</td>\n      <td>0.829393</td>\n      <td>0.962260</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.230200</td>\n      <td>0.147838</td>\n      <td>0.961749</td>\n      <td>0.962917</td>\n      <td>0.993795</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.168300</td>\n      <td>0.031781</td>\n      <td>0.990035</td>\n      <td>0.990364</td>\n      <td>0.999573</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.142900</td>\n      <td>0.065483</td>\n      <td>0.985857</td>\n      <td>0.986155</td>\n      <td>0.998567</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.121000</td>\n      <td>0.148514</td>\n      <td>0.959499</td>\n      <td>0.959250</td>\n      <td>0.998137</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.096800</td>\n      <td>0.268934</td>\n      <td>0.939569</td>\n      <td>0.937831</td>\n      <td>0.999109</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.090500</td>\n      <td>0.032272</td>\n      <td>0.992285</td>\n      <td>0.992476</td>\n      <td>0.999525</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.085400</td>\n      <td>0.052890</td>\n      <td>0.985214</td>\n      <td>0.985471</td>\n      <td>0.999798</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.074200</td>\n      <td>0.011355</td>\n      <td>0.996143</td>\n      <td>0.996259</td>\n      <td>0.999893</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.072700</td>\n      <td>0.051637</td>\n      <td>0.989392</td>\n      <td>0.989626</td>\n      <td>0.999827</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.069100</td>\n      <td>0.049002</td>\n      <td>0.989071</td>\n      <td>0.989308</td>\n      <td>0.999604</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.074700</td>\n      <td>0.058778</td>\n      <td>0.986500</td>\n      <td>0.986751</td>\n      <td>0.999855</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.052400</td>\n      <td>0.098090</td>\n      <td>0.985857</td>\n      <td>0.986129</td>\n      <td>0.999575</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.060500</td>\n      <td>0.016225</td>\n      <td>0.995500</td>\n      <td>0.995625</td>\n      <td>0.999983</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.038000</td>\n      <td>0.016759</td>\n      <td>0.995178</td>\n      <td>0.995311</td>\n      <td>0.999978</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.049300</td>\n      <td>0.006193</td>\n      <td>0.998393</td>\n      <td>0.998445</td>\n      <td>0.999987</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.051800</td>\n      <td>0.018372</td>\n      <td>0.994857</td>\n      <td>0.995028</td>\n      <td>0.999948</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.052800</td>\n      <td>0.015370</td>\n      <td>0.995178</td>\n      <td>0.995329</td>\n      <td>0.999947</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.046100</td>\n      <td>0.023948</td>\n      <td>0.995500</td>\n      <td>0.995625</td>\n      <td>0.999963</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.042700</td>\n      <td>0.033714</td>\n      <td>0.992928</td>\n      <td>0.993103</td>\n      <td>0.999976</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.028700</td>\n      <td>0.024384</td>\n      <td>0.996143</td>\n      <td>0.996250</td>\n      <td>0.999976</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.022500</td>\n      <td>0.070546</td>\n      <td>0.988107</td>\n      <td>0.988354</td>\n      <td>0.999935</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.018000</td>\n      <td>0.032403</td>\n      <td>0.994536</td>\n      <td>0.994679</td>\n      <td>0.999978</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.028200</td>\n      <td>0.013371</td>\n      <td>0.997750</td>\n      <td>0.997816</td>\n      <td>0.999989</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["import pandas as pd\n","from tqdm import tqdm\n","\n","model.eval()\n","ids = []\n","probs = []\n","\n","for batch in tqdm(test_data):\n","    id = batch[\"id\"]\n","    audio = batch[\"audio\"][\"array\"]\n","    inputs = feature_extractor(audio, sampling_rate=16000, return_tensors=\"pt\",padding=True)\n","\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        prob = F.softmax(logits, dim=1)\n","        #prob_fake = prob[:,1].item()\n","        prob_synth = prob[:,1].item()\n","        ids.append(id)\n","        probs.append(prob_synth)\n","\n","\n","df = pd.DataFrame({\"id\": ids, \"is_tts\" : probs})"],"metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-10T13:24:13.228Z"},"id":"5my7E_SbUoR5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["df.to_csv(\"/kaggle/working/submission.csv\", index=False)"],"metadata":{"trusted":true,"id":"3kWFbmjcUoR5"},"outputs":[],"execution_count":null}]}