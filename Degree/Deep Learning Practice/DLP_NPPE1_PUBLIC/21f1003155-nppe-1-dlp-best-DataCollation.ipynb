{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbab2e9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-18T02:58:12.215237Z",
     "iopub.status.busy": "2025-02-18T02:58:12.214920Z",
     "iopub.status.idle": "2025-02-18T02:58:13.553419Z",
     "shell.execute_reply": "2025-02-18T02:58:13.552476Z"
    },
    "papermill": {
     "duration": 1.347086,
     "end_time": "2025-02-18T02:58:13.554941",
     "exception": false,
     "start_time": "2025-02-18T02:58:12.207855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n",
      "/kaggle/input/multi-lingual-sentiment-analysis/sample_submission.csv\n",
      "/kaggle/input/multi-lingual-sentiment-analysis/train.csv\n",
      "/kaggle/input/multi-lingual-sentiment-analysis/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabc5324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T02:58:13.567900Z",
     "iopub.status.busy": "2025-02-18T02:58:13.567454Z",
     "iopub.status.idle": "2025-02-18T03:02:01.896287Z",
     "shell.execute_reply": "2025-02-18T03:02:01.895290Z"
    },
    "papermill": {
     "duration": 228.336932,
     "end_time": "2025-02-18T03:02:01.897944",
     "exception": false,
     "start_time": "2025-02-18T02:58:13.561012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\r\n",
      "  Downloading unsloth-2025.2.12-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.2.5 (from unsloth)\r\n",
      "  Downloading unsloth_zoo-2025.2.5-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\r\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\r\n",
      "  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\r\n",
      "Collecting bitsandbytes (from unsloth)\r\n",
      "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\r\n",
      "Collecting triton>=3.0.0 (from unsloth)\r\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\r\n",
      "Collecting tyro (from unsloth)\r\n",
      "  Downloading tyro-0.9.14-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Collecting transformers!=4.47.0,>=4.46.1 (from unsloth)\r\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.2.0)\r\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\r\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\r\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\r\n",
      "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\r\n",
      "  Downloading trl-0.15.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\r\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\r\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.28.1)\r\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\r\n",
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.31.0)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.17.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (19.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.9.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.11)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\r\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.2.5->unsloth)\r\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.2.5->unsloth) (11.0.0)\r\n",
      "Collecting torch>=2.4.0 (from unsloth)\r\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\r\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting torchvision (from unsloth)\r\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\r\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\r\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.19.1)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\r\n",
      "Downloading unsloth-2025.2.12-py3-none-any.whl (187 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading trl-0.15.0-py3-none-any.whl (318 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.3/318.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.2.5-py3-none-any.whl (105 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m947.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tyro-0.9.14-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\r\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.5.1+cu121\r\n",
      "    Uninstalling torch-2.5.1+cu121:\r\n",
      "      Successfully uninstalled torch-2.5.1+cu121\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.47.0\r\n",
      "    Uninstalling transformers-4.47.0:\r\n",
      "      Successfully uninstalled transformers-4.47.0\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.20.1+cu121\r\n",
      "    Uninstalling torchvision-0.20.1+cu121:\r\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.45.2 cut_cross_entropy-25.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.6.0 torchvision-0.21.0 transformers-4.49.0 triton-3.2.0 trl-0.15.0 tyro-0.9.14 unsloth-2025.2.12 unsloth_zoo-2025.2.5 xformers-0.0.29.post3\r\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# !pip install bitsandbytes\n",
    "# !pip install unsloth\n",
    "# !pip install accelerate\n",
    "# !pip install peft\n",
    "# !pip install torch==2.1.2 --force-reinstall\n",
    "# !pip install --upgrade transformers\n",
    "!pip install --upgrade unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16383a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:02.009259Z",
     "iopub.status.busy": "2025-02-18T03:02:02.008928Z",
     "iopub.status.idle": "2025-02-18T03:02:08.357740Z",
     "shell.execute_reply": "2025-02-18T03:02:08.356983Z"
    },
    "papermill": {
     "duration": 6.406165,
     "end_time": "2025-02-18T03:02:08.359344",
     "exception": false,
     "start_time": "2025-02-18T03:02:01.953179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashwinhebbar\u001b[0m (\u001b[33mashwinhebbar-indian-institute-of-technology-madras\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250218_030205-ujo759e5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdauntless-wildflower-28\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ashwinhebbar-indian-institute-of-technology-madras/DLP%20NPPE%201\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ashwinhebbar-indian-institute-of-technology-madras/DLP%20NPPE%201/runs/ujo759e5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wb_token = \"3cd4edf5d9787b37cbc32e75bee1e74b81972f25\"\n",
    "wandb.login(key=wb_token)\n",
    "\n",
    "run = wandb.init(\n",
    "    project='DLP NPPE 1', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af18a912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:08.471642Z",
     "iopub.status.busy": "2025-02-18T03:02:08.471301Z",
     "iopub.status.idle": "2025-02-18T03:02:10.207503Z",
     "shell.execute_reply": "2025-02-18T03:02:10.206738Z"
    },
    "papermill": {
     "duration": 1.79354,
     "end_time": "2025-02-18T03:02:10.209273",
     "exception": false,
     "start_time": "2025-02-18T03:02:08.415733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "\n",
    "testset = \"/kaggle/input/multi-lingual-sentiment-analysis/test.csv\"\n",
    "\n",
    "df = pd.read_csv(testset)\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72628d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:10.321620Z",
     "iopub.status.busy": "2025-02-18T03:02:10.321286Z",
     "iopub.status.idle": "2025-02-18T03:02:10.326991Z",
     "shell.execute_reply": "2025-02-18T03:02:10.326290Z"
    },
    "papermill": {
     "duration": 0.062704,
     "end_time": "2025-02-18T03:02:10.328244",
     "exception": false,
     "start_time": "2025-02-18T03:02:10.265540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a582d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:10.504123Z",
     "iopub.status.busy": "2025-02-18T03:02:10.503721Z",
     "iopub.status.idle": "2025-02-18T03:02:10.541366Z",
     "shell.execute_reply": "2025-02-18T03:02:10.540183Z"
    },
    "papermill": {
     "duration": 0.098883,
     "end_time": "2025-02-18T03:02:10.543909",
     "exception": false,
     "start_time": "2025-02-18T03:02:10.445026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset = \"/kaggle/input/multi-lingual-sentiment-analysis/train.csv\"\n",
    "\n",
    "train_df = pd.read_csv(trainset)\n",
    "\n",
    "# train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "519008c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:10.688293Z",
     "iopub.status.busy": "2025-02-18T03:02:10.687941Z",
     "iopub.status.idle": "2025-02-18T03:02:10.710316Z",
     "shell.execute_reply": "2025-02-18T03:02:10.709278Z"
    },
    "papermill": {
     "duration": 0.090974,
     "end_time": "2025-02-18T03:02:10.711827",
     "exception": false,
     "start_time": "2025-02-18T03:02:10.620853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1000, 4) (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_size = 1.0\n",
    "# eval_size = 0.1\n",
    "\n",
    "X_train = train_df[:int(train_size*10 * len(df))]\n",
    "X_train_dataset = Dataset.from_pandas(X_train)\n",
    "# X_eval = train_df[int(train_size*10 * len(df)):]\n",
    "# X_eval_dataset = Dataset.from_pandas(X_eval)\n",
    "# print(\"X_eval.shape:\", X_eval.shape, X_eval_dataset.shape)\n",
    "print(\"X_train.shape:\", X_train.shape, X_train_dataset.shape)\n",
    "# X_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f568767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:10.844392Z",
     "iopub.status.busy": "2025-02-18T03:02:10.844002Z",
     "iopub.status.idle": "2025-02-18T03:02:10.848601Z",
     "shell.execute_reply": "2025-02-18T03:02:10.847725Z"
    },
    "papermill": {
     "duration": 0.067667,
     "end_time": "2025-02-18T03:02:10.850109",
     "exception": false,
     "start_time": "2025-02-18T03:02:10.782442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_dict = {\"as\": \"Assamese\", \"bd\": \"Bodo\", \"bn\": \"Bengali\", \"gu\": \"Gujarati\", \"hi\": \"Hindi\", \"kn\": \"Kannada\", \"ml\": \"Malayalam\", \"mr\": \"Marathi\", \"or\": \"Odia\", \"pa\": \"Punjabi\", \"ta\": \"Tamil\", \"te\": \"Telugu\", \"ur\": \"Urdu\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bda29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:10.970075Z",
     "iopub.status.busy": "2025-02-18T03:02:10.969710Z",
     "iopub.status.idle": "2025-02-18T03:02:10.975830Z",
     "shell.execute_reply": "2025-02-18T03:02:10.974793Z"
    },
    "papermill": {
     "duration": 0.067565,
     "end_time": "2025-02-18T03:02:10.977302",
     "exception": false,
     "start_time": "2025-02-18T03:02:10.909737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_train_prompt(language_data):\n",
    "    return f\"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There's no options such as \"Neutral\" or anything else. It's only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Examples:\n",
    "1. Language: Bodo\n",
    "Text: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\n",
    "Output: {{\"sentiment\": \"Negative\"}}\n",
    "\n",
    "2. Language: Telugu\n",
    "Text: కొన్ని మంచి బ్యాండ్‌లు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\n",
    "Output: {{\"sentiment\": \"Positive\"}}\n",
    "\n",
    "3. Language: Tamil\n",
    "Text: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\n",
    "Output: {{\"sentiment\": \"Positive\"}}\n",
    "\n",
    "Current Input:\n",
    "Language: {map_dict[language_data['language']]}\n",
    "Text: {language_data[\"sentence\"]}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{{\"sentiment\": \"{language_data[\"label\"]}\"}}<|eot_id|>\"\"\"\n",
    "\n",
    "def generate_test_prompt(language_data):\n",
    "    return f\"\"\"<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There's no options such as \"Neutral\" or anything else. It's only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Examples:\n",
    "1. Language: Bodo\n",
    "Text: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\n",
    "Output: {{\"sentiment\": \"Negative\"}}\n",
    "\n",
    "2. Language: Telugu\n",
    "Text: కొన్ని మంచి బ్యాండ్‌లు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\n",
    "Output: {{\"sentiment\": \"Positive\"}}\n",
    "\n",
    "3. Language: Tamil\n",
    "Text: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\n",
    "Output: {{\"sentiment\": \"Positive\"}}\n",
    "Current Input:\n",
    "Language: {map_dict[language_data['language']]}\n",
    "Text: {language_data[\"sentence\"]}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa50807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:11.096620Z",
     "iopub.status.busy": "2025-02-18T03:02:11.096319Z",
     "iopub.status.idle": "2025-02-18T03:02:11.222842Z",
     "shell.execute_reply": "2025-02-18T03:02:11.221924Z"
    },
    "papermill": {
     "duration": 0.188361,
     "end_time": "2025-02-18T03:02:11.224375",
     "exception": false,
     "start_time": "2025-02-18T03:02:11.036014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b872b575087e4775afe29a53d921b2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_row_function_train(example):\n",
    "    return {\n",
    "        \"text\": generate_train_prompt({\n",
    "            \"language\": example[\"language\"],\n",
    "            \"sentence\": example[\"sentence\"],\n",
    "            \"label\": example[\"label\"]\n",
    "        })\n",
    "    }\n",
    "\n",
    "\n",
    "def format_row_function_test(example):\n",
    "    return {\n",
    "        \"text\": generate_test_prompt({\n",
    "            \"language\": example[\"language\"],\n",
    "            \"sentence\": example[\"sentence\"],\n",
    "            \"label\": example[\"label\"]\n",
    "        })\n",
    "    }\n",
    "\n",
    "lm_train_dataset = X_train_dataset.map(\n",
    "    format_row_function_train,\n",
    "    remove_columns=[\"ID\", \"language\", \"sentence\", \"label\"],\n",
    "    batched=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62398d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:11.336743Z",
     "iopub.status.busy": "2025-02-18T03:02:11.336428Z",
     "iopub.status.idle": "2025-02-18T03:02:11.345492Z",
     "shell.execute_reply": "2025-02-18T03:02:11.344365Z"
    },
    "papermill": {
     "duration": 0.065947,
     "end_time": "2025-02-18T03:02:11.346928",
     "exception": false,
     "start_time": "2025-02-18T03:02:11.280981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1000\n",
      "Sample training prompt:\n",
      " <|begin_of_text|>\n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "You are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There's no options such as \"Neutral\" or anything else. It's only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Examples:\n",
      "1. Language: Bodo\n",
      "Text: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\n",
      "Output: {\"sentiment\": \"Negative\"}\n",
      "\n",
      "2. Language: Telugu\n",
      "Text: కొన్ని మంచి బ్యాండ్‌లు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\n",
      "Output: {\"sentiment\": \"Positive\"}\n",
      "\n",
      "3. Language: Tamil\n",
      "Text: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\n",
      "Output: {\"sentiment\": \"Positive\"}\n",
      "\n",
      "Current Input:\n",
      "Language: Bengali\n",
      "Text: কর্মীদের ভাল আচরণ এবং খাবারের পাশাপাশি পানীয় (ককটেল এবং মকটেল) সহ একটি অনন্য জায়গা খুবই ভাল। প্রায়ই একটি সরাসরি সঙ্গীত পরিবেশনের সাথে এমন পরিবেশ তৈরী করে যে একজন দিন এবং সন্ধ্যা উভয় সময়েই জায়গাটি উপভোগ করতে পারে।<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "{\"sentiment\": \"Positive\"}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples:\", len(lm_train_dataset))\n",
    "print(\"Sample training prompt:\\n\", lm_train_dataset[0][\"text\"])\n",
    "# print(\"--\"*25)\n",
    "# print(\"\\nEvaluation samples:\", len(lm_eval_dataset))\n",
    "# print(\"Sample eval prompt:\\n\", lm_eval_dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "643bcace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:11.457824Z",
     "iopub.status.busy": "2025-02-18T03:02:11.457483Z",
     "iopub.status.idle": "2025-02-18T03:02:11.461906Z",
     "shell.execute_reply": "2025-02-18T03:02:11.461056Z"
    },
    "papermill": {
     "duration": 0.061218,
     "end_time": "2025-02-18T03:02:11.463180",
     "exception": false,
     "start_time": "2025-02-18T03:02:11.401962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt, model, tokenizer, json_schema=None, max_length=1024):\n",
    "    # Tokenize input prompt and move to the correct device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs)\n",
    "    # jsonformer = Jsonformer(model, tokenizer, json_schema, prompt)\n",
    "\n",
    "    # Decode and return generated text\n",
    "    # return jsonformer()\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad5eb1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:11.572643Z",
     "iopub.status.busy": "2025-02-18T03:02:11.572300Z",
     "iopub.status.idle": "2025-02-18T03:02:11.576341Z",
     "shell.execute_reply": "2025-02-18T03:02:11.575594Z"
    },
    "papermill": {
     "duration": 0.06052,
     "end_time": "2025-02-18T03:02:11.577525",
     "exception": false,
     "start_time": "2025-02-18T03:02:11.517005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "# # from unsloth import FastLanguageModel\n",
    "# model_path = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
    "\n",
    "\n",
    "# # Quantization configuration\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "# )\n",
    "\n",
    "# # Loading the model and tokenizer\n",
    "\n",
    "\n",
    "\n",
    "# # device_map = {\n",
    "# #     \"model.embed_tokens\": 0,\n",
    "# #     \"model.layers.0\": 0,\n",
    "# #     \"model.layers.1\": 0,\n",
    "# #     \"model.layers.2\": 0,\n",
    "# #     \"model.layers.3\": 0,\n",
    "# #     \"model.layers.4\": 0,\n",
    "# #     \"model.layers.5\": 0,\n",
    "# #     \"model.layers.6\": 1,\n",
    "# #     \"model.layers.7\": 1,\n",
    "# #     \"model.layers.8\": 1,\n",
    "# #     \"model.layers.9\": 1,\n",
    "# #     \"model.layers.10\": 1,\n",
    "# #     \"model.layers.11\": 1,\n",
    "# #     \"lm_head\": 1\n",
    "# # }\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "#                                              quantization_config=bnb_config,\n",
    "#                                              device_map=\"auto\")\n",
    "\n",
    "# model.config.use_cache = False\n",
    "# model.config.pretraining_tp = 1\n",
    "# # model = torch.compile(model)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_path,\n",
    "#     model_max_length=1024,\n",
    "#     padding_side=\"right\",\n",
    "#     use_fast=True,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     # add_special_tokens=False,  # Set here\n",
    "#     # add_eos_token=True\n",
    "# )\n",
    "\n",
    "# tokenizer.add_special_tokens({\n",
    "#     \"additional_special_tokens\": [\n",
    "#         \"<|begin_of_text|>\",\n",
    "#         \"<|start_header_id|>\",\n",
    "#         \"<|end_header_id|>\",\n",
    "#         \"<|eot_id|>\"\n",
    "#     ]\n",
    "# })\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# # model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "# #     model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "# #     max_seq_length = 1200,  # Reduced from 1536\n",
    "# #     dtype = None,\n",
    "# #     load_in_4bit = True,\n",
    "# #     attn_implementation = \"flash_attention_2\",  # 50% memory reduction\n",
    "# # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "690d755c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:02:11.685092Z",
     "iopub.status.busy": "2025-02-18T03:02:11.684738Z",
     "iopub.status.idle": "2025-02-18T03:04:22.351975Z",
     "shell.execute_reply": "2025-02-18T03:04:22.350921Z"
    },
    "papermill": {
     "duration": 130.723305,
     "end_time": "2025-02-18T03:04:22.353814",
     "exception": false,
     "start_time": "2025-02-18T03:02:11.630509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b651f9b4344048298d99ed7bdfbb8358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2 does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model_path = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "map_dict = {\n",
    "    \"as\": \"Assamese\", \"bd\": \"Bodo\",\n",
    "    \"bn\": \"Bengali\", \"gu\": \"Gujarati\",\n",
    "    \"hi\": \"Hindi\", \"kn\": \"Kannada\",\n",
    "    \"ml\": \"Malayalam\", \"mr\": \"Marathi\",\n",
    "    \"or\": \"Odia\", \"pa\": \"Punjabi\", \"ta\": \"Tamil\",\n",
    "    \"te\": \"Telugu\", \"ur\": \"Urdu\"\n",
    "}\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_path,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True\n",
    ")\n",
    "\n",
    "\n",
    "# Adding LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60aa94be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:22.469552Z",
     "iopub.status.busy": "2025-02-18T03:04:22.469161Z",
     "iopub.status.idle": "2025-02-18T03:04:22.472973Z",
     "shell.execute_reply": "2025-02-18T03:04:22.472071Z"
    },
    "papermill": {
     "duration": 0.063422,
     "end_time": "2025-02-18T03:04:22.474419",
     "exception": false,
     "start_time": "2025-02-18T03:04:22.410997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import bitsandbytes as bnb\n",
    "\n",
    "# def find_all_linear_names(model):\n",
    "#     cls = bnb.nn.Linear4bit\n",
    "#     lora_module_names = set()\n",
    "#     for name, module in model.named_modules():\n",
    "#         if isinstance(module, cls):\n",
    "#             names = name.split('.')\n",
    "#             lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "#     if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "#         lora_module_names.remove('lm_head')\n",
    "#     return list(lora_module_names)\n",
    "# modules = find_all_linear_names(model)\n",
    "# modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7380c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:22.584656Z",
     "iopub.status.busy": "2025-02-18T03:04:22.584320Z",
     "iopub.status.idle": "2025-02-18T03:04:23.074872Z",
     "shell.execute_reply": "2025-02-18T03:04:23.074126Z"
    },
    "papermill": {
     "duration": 0.546704,
     "end_time": "2025-02-18T03:04:23.076186",
     "exception": false,
     "start_time": "2025-02-18T03:04:22.529482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a328316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:23.185092Z",
     "iopub.status.busy": "2025-02-18T03:04:23.184769Z",
     "iopub.status.idle": "2025-02-18T03:04:30.065516Z",
     "shell.execute_reply": "2025-02-18T03:04:30.064471Z"
    },
    "papermill": {
     "duration": 6.936928,
     "end_time": "2025-02-18T03:04:30.066907",
     "exception": false,
     "start_time": "2025-02-18T03:04:23.129979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9afb39194cb4c029290ac78f25f05de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bb9155f5ef4ed29ab1875cabfc8157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c67b6352cf342ed9458d0d576a40b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# from peft import LoraConfig, PeftConfig\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from trl import SFTTrainer\n",
    "# from trl import SFTConfig\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# output_dir=\"llama-fine-tuned-model\"\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     lora_alpha=8,\n",
    "#     lora_dropout=0,\n",
    "#     r=4,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],\n",
    "#     inference_mode=False,\n",
    "# )\n",
    "\n",
    "# training_arguments = SFTConfig(\n",
    "#     output_dir=output_dir,                    # directory to save and repository id\n",
    "#     # num_train_epochs=1,                       # number of training epochs\n",
    "#     per_device_train_batch_size=1,            # batch size per device during training\n",
    "#     gradient_accumulation_steps=4,            # number of steps before performing a backward/update pass\n",
    "#     gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "#     optim=\"paged_adamw_8bit\",\n",
    "#     learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "#     weight_decay=0.001,\n",
    "#     fp16=True,\n",
    "#     bf16=False,\n",
    "#     max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "#     warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "#     logging_steps=1,                         \n",
    "#     max_steps=20,\n",
    "#     group_by_length=True,\n",
    "#     lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "#     report_to=\"wandb\",                  # report metrics to w&b\n",
    "#     eval_strategy=\"steps\",              # save checkpoint every epoch\n",
    "#     eval_steps = 5,\n",
    "#     dataset_text_field=\"text\",\n",
    "#     max_seq_length=1024,\n",
    "# )\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     args=training_arguments,\n",
    "#     train_dataset=lm_train_dataset,\n",
    "#     eval_dataset=lm_eval_dataset,\n",
    "#     peft_config=peft_config,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = lm_train_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 2, # Set this for 1 full training run.\n",
    "        max_steps=80,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 1337,\n",
    "        output_dir = \"fine-tuned\",\n",
    "        report_to = \"wandb\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6be1741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:30.180536Z",
     "iopub.status.busy": "2025-02-18T03:04:30.180014Z",
     "iopub.status.idle": "2025-02-18T03:04:30.186187Z",
     "shell.execute_reply": "2025-02-18T03:04:30.185270Z"
    },
    "papermill": {
     "duration": 0.064924,
     "end_time": "2025-02-18T03:04:30.187705",
     "exception": false,
     "start_time": "2025-02-18T03:04:30.122781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\nCurrent Input:\\nLanguage: Bengali\\nText: কর্মীদের ভাল আচরণ এবং খাবারের পাশাপাশি পানীয় (ককটেল এবং মকটেল) সহ একটি অনন্য জায়গা খুবই ভাল। প্রায়ই একটি সরাসরি সঙ্গীত পরিবেশনের সাথে এমন পরিবেশ তৈরী করে যে একজন দিন এবং সন্ধ্যা উভয় সময়েই জায়গাটি উপভোগ করতে পারে।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n{\"sentiment\": \"Positive\"}<|eot_id|>'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806f8cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:30.301991Z",
     "iopub.status.busy": "2025-02-18T03:04:30.301660Z",
     "iopub.status.idle": "2025-02-18T03:04:31.335541Z",
     "shell.execute_reply": "2025-02-18T03:04:31.334537Z"
    },
    "papermill": {
     "duration": 1.093213,
     "end_time": "2025-02-18T03:04:31.337234",
     "exception": false,
     "start_time": "2025-02-18T03:04:30.244021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87da073b716248b89f8c0c1efbe92a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "842d5f30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:31.451390Z",
     "iopub.status.busy": "2025-02-18T03:04:31.451031Z",
     "iopub.status.idle": "2025-02-18T03:04:31.464982Z",
     "shell.execute_reply": "2025-02-18T03:04:31.464195Z"
    },
    "papermill": {
     "duration": 0.073755,
     "end_time": "2025-02-18T03:04:31.466241",
     "exception": false,
     "start_time": "2025-02-18T03:04:31.392486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\nCurrent Input:\\nLanguage: Assamese\\nText: ইয়াত বহুতো জনপ্ৰিয় কিতাপ বিনামূলীয়াকৈ উপলব্ধ। এক বৃহৎ অডিঅ\\' সক্ষম সমল আছে যি 5 টা ভাৰতীয় ভাষাত উপলব্ধ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n{\"sentiment\": \"Positive\"}<|eot_id|>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd014ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:04:31.580708Z",
     "iopub.status.busy": "2025-02-18T03:04:31.580375Z",
     "iopub.status.idle": "2025-02-18T03:18:27.965903Z",
     "shell.execute_reply": "2025-02-18T03:18:27.965060Z"
    },
    "papermill": {
     "duration": 836.445424,
     "end_time": "2025-02-18T03:18:27.967334",
     "exception": false,
     "start_time": "2025-02-18T03:04:31.521910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 4 | Total steps = 80\n",
      " \"-____-\"     Number of trainable parameters = 20,971,520\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 13:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.190700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.194700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>-0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.245400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.260300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.05834305544017297, metrics={'train_runtime': 834.2188, 'train_samples_per_second': 0.384, 'train_steps_per_second': 0.096, 'total_flos': 1.4966840067784704e+16, 'train_loss': 0.05834305544017297})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "648e8395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:18:28.084700Z",
     "iopub.status.busy": "2025-02-18T03:18:28.084361Z",
     "iopub.status.idle": "2025-02-18T03:18:28.101168Z",
     "shell.execute_reply": "2025-02-18T03:18:28.100319Z"
    },
    "papermill": {
     "duration": 0.076481,
     "end_time": "2025-02-18T03:18:28.102523",
     "exception": false,
     "start_time": "2025-02-18T03:18:28.026042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "700fbdd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:18:28.219467Z",
     "iopub.status.busy": "2025-02-18T03:18:28.219058Z",
     "iopub.status.idle": "2025-02-18T03:18:28.222404Z",
     "shell.execute_reply": "2025-02-18T03:18:28.221635Z"
    },
    "papermill": {
     "duration": 0.063726,
     "end_time": "2025-02-18T03:18:28.223691",
     "exception": false,
     "start_time": "2025-02-18T03:18:28.159965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = generate_response(lm_eval_dataset[1][\"text\"], model, tokenizer,max_length=1024)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c45fdf9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:18:28.341592Z",
     "iopub.status.busy": "2025-02-18T03:18:28.341184Z",
     "iopub.status.idle": "2025-02-18T03:18:28.347135Z",
     "shell.execute_reply": "2025-02-18T03:18:28.346362Z"
    },
    "papermill": {
     "duration": 0.067526,
     "end_time": "2025-02-18T03:18:28.348485",
     "exception": false,
     "start_time": "2025-02-18T03:18:28.280959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def eval_model(model, dataset):\n",
    "    length = len(dataset)\n",
    "    sentimentlist = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        print(\"--------------\")\n",
    "        print(\"Instance\", i)\n",
    "        print(\"--------------\")\n",
    "        print(f\"checking for {dataset[i]}\")\n",
    "        try:\n",
    "            uncleaned_output = generate_response(dataset[i][\"text\"], model, tokenizer, max_length = 1024)\n",
    "            output = json.loads(uncleaned_output.split(\"assistant\")[1].lstrip(\"\\n```json\\n\").rstrip(\"\\n```\"))\n",
    "            print(f\"\\tPredicted Sentiment: {output['sentiment']}\")\n",
    "            sentimentlist.append(output['sentiment'])\n",
    "        except RuntimeError:\n",
    "            sentimentlist.append(\"ERROR\") \n",
    "        \n",
    "    return sentimentlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4920dcf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:18:28.464702Z",
     "iopub.status.busy": "2025-02-18T03:18:28.464344Z",
     "iopub.status.idle": "2025-02-18T03:18:28.500122Z",
     "shell.execute_reply": "2025-02-18T03:18:28.499147Z"
    },
    "papermill": {
     "duration": 0.095212,
     "end_time": "2025-02-18T03:18:28.501703",
     "exception": false,
     "start_time": "2025-02-18T03:18:28.406491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e98a6c0d7cd4bf4aea01143c07f1cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_row_function_test(example):\n",
    "    return {\n",
    "        \"text\": generate_test_prompt({\n",
    "            \"language\": example[\"language\"],\n",
    "            \"sentence\": example[\"sentence\"],\n",
    "        })\n",
    "    }\n",
    "\n",
    "test_dataset_input = test_dataset.map(\n",
    "    format_row_function_test,\n",
    "    remove_columns=[\"ID\", \"language\", \"sentence\"],\n",
    "    batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f41190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:18:28.616512Z",
     "iopub.status.busy": "2025-02-18T03:18:28.616128Z",
     "iopub.status.idle": "2025-02-18T03:20:53.273596Z",
     "shell.execute_reply": "2025-02-18T03:20:53.272515Z"
    },
    "papermill": {
     "duration": 144.717106,
     "end_time": "2025-02-18T03:20:53.275181",
     "exception": false,
     "start_time": "2025-02-18T03:18:28.558075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Instance 0\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: 1120 mAh, ਓਵਰਚਾਰਜਿੰਗ ਦੀ ਸੁਰੱਖਿਆ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 1\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: તે સઘન મોઇશ્ચરાઇઝિંગ પ્રદાન કરે છે અને સરસ સ્વર્ગીય ફળની સુગંધ આપે છે<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 2\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: 1120 ಎಂಎಎಚ್, ಮಿತಿಮೀರಿದ ರಕ್ಷಣೆ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 3\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: ভাৰতত নিৰ্মিত সৰ্বশ্ৰেষ্ঠ পাৰফিউম ব্ৰেণ্ডবোৰৰ এটা। এইটো এটা নিশ্চিতভাৱে পৰীক্ষণীয় সামগ্ৰী। মই বিভিন্ন স্তৰৰ কমলাৰ ফুল, আঙুৰ, কস্তুৰী আৰু জেচমিনৰ গোন্ধ ভাল পাওঁ। সঁচাকৈয়ে আপোনাক গোটেই দিনটো সতেজ কৰি ৰাখে।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 4\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: میں نے حال ہی میں \"انفولڈ\" سے ایک ٹیمپلیٹ خریدا ہے لیکن میں اپنے ترمیمی صفحہ تک رسائی یا دیکھنے سے قاصر ہوں۔ یہ کافی پریشان کن ہے، بینک اکاؤنٹ سے رقم کاٹی جا رہی ہے اور ٹیمپلیٹ دکھا رہا ہے، لیکن ترمیم کے موڈ میں ظاہر نہیں ہوتا ہے۔<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 5\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: వెలుపలి నుంచి నియాప్రీన్ మెటీరియల్ కోటింగ్ ఉంటుంది, అయితే లోపలి నుంచి ఎలాంటి కవరింగ్ ఉండదు, అందువల్ల బంప్\\u200cల నుంచి లెన్స్\\u200cని అంత సమర్థవంతంగా సంరక్షించలేం.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 6\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: 1120 mAh, ஓவர் சார்ஜ் பாதுகாப்பு<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 7\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: ഉഷയിൽ നിന്നുള്ള ഈ പേഴ്സണൽ എയർ കൂളർ വളരെ മിനുസമാർന്ന ബ്ലോവറോടെയാണ് വരുന്നത്, നിങ്ങൾക്ക് ഇത് ഒരു കൂളറായി തോന്നില്ല, മറിച്ച് ഒരു ഫാൻ പോലെയാണ്. ശബ്\\u200cദ നില വളരെ കുറവാണ്.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 8\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: কিন্তু আপনি এই পণ্যের ফ্লাইট/স্থায়িত্বের ক্ষেত্রে গুণমানের আশা করতে পারবেন না। এই শাটলটা 10 মিনিটের এক গেমে ভেঙে গেছে, ওরা যেন আমার টাকা ফেরত দেয়।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 9\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: এখানে অ্যাপে আপনি কি শেয়ার করবেন তার নিয়ন্ত্রণ আপনার কাছে থাকে। এবং তারা আসলেই আপনার পার্সোনাল স্পেসে প্রবেশ করে না।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 10\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: బజాజ్ టవర్ ఎయిర్ కూలర్ సూపర్ స్లీక్ మరియు సొగసైన డిజైన్\\u200c ఉంటుంది. ఇది ఉపయోగంతో కూడిన ఒక కళాఖండంలా కనిపిస్తుంది, సంప్రదాయ సూత్రం లేదా ఆర్ట్\\u200cని గుర్తు చేస్తుంది.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 11\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: పాత బాడీ షేమింగ్ జోక్\\u200cలు, మమ్మల్ని నవ్వించడానికి చాలా కష్టపడతాయి. ట్రైలర్ చూస్తే సినిమా గురించి ఇప్పటికే 90% తెలిసిపోతుంది<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 12\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: یہ ایک خوفناک پروڈکٹ ہے!! یہ صرف چند گھنٹوں کے لئے کام کرتا ہے۔ میرے لیے یہ چار گھنٹے سے زیادہ دیر تک نہیں رہتی ہے۔ خریدنے کی سفارش نہ کریں!!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 13\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: ಪ್ರಬಲವಾದ ಶಕ್ತಿಯುತವಾದ ಪರಿಮಳವನ್ನು ಹೊಂದಿದೆ, ಅದು ಕಾಲಹರಣ ಮಾಡುತ್ತದೆ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 14\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: वे अपनी विश्व स्तरीय इंजीनियरिंग, हाई स्पीड पोटेंशियल, यूनिक स्टाइल और दुनिया भर में डीलरशिप सपोर्ट के लिए जाने जाते हैं।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 15\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: ଏହା ମଧ୍ୟମ ଫର୍ମାଟ୍ 120 ରୋଲ୍ ଫିଲ୍ମରେ ଏହା 12 ଫ୍ରେମ୍ ସୁଟ୍ କରେ, ଫିଲ୍ଡ ଇଫେକ୍ଟର ଅଳ୍ପ ଗଭୀରତା ସହିତ ଆମେ ଆଧୁନିକ କ୍ୟାମେରା ସହିତ ହାସଲ କରିବାକୁ ଭାଗ୍ୟ ଦେଇଥାଉ |<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 16\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: লাম্বার সাপোর্ট এবং হেডরেস্ট 5\\'8\" এর উপরে থাকা মানুষের জন্য উপযুক্ত নয়, এবং আর্মরেস্ট অনেক সময় নড়াচড়া করে তখন এটি আপনাকে বিরক্তিকর অভিজ্ঞতা দেয়। এছাড়াও, এর মূল্য অনেক বেশি!!! একজন মধ্যবিত্ত ক্রেতার জন্য এটা মোটেও সাশ্রয়ী নয়।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 17\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: \"અંદરના ભાગના નગરો અને જિલ્લા મુખ્યાલયોની કનેક્ટિવિટી ખૂબ નબળી છે.\"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 18\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: பெற்றோர்கள் தோன்றும் ஒவ்வொரு காட்சியிலும் அவர்கள் இரட்டைக் குழந்தைகளாக இருந்த 2 உடன்பிறப்புகளைப் பிரித்துவிட்டு, தங்கள் சொந்த தொழில்/நல்வாழ்வுக்காக அதைப் பற்றி அவர்களிடம் சொல்லாமல் இருந்ததற்காக அவர்களுக்கு எந்த வருத்தமும் இல்லை. ஒருமுறை கூட பெற்றோர்கள் இருவரும் தங்களோடு வசிக்காத மற்றொரு குழந்தையை அழைக்கவில்லை அல்லது அவர்கள் என்ன செய்கிறார்கள் என்று யோசிக்கவில்லை.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 19\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: चॉइस ऑफ़ कास्ट, और उनकी परफॉर्मेंस बेहतरीन थी!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 20\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: हाई कलर रेंडरिंग इंडेक्स (सीआरआई>96, टीएलसीआई≥98) वस्तुओं को प्रामाणिक रूप से प्रस्तुत करने के लिए, प्रीमियम एल्यूमीनियम बेस्ड बिल्ड<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 21\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: रनबिरनि फाव खालामनाया नांनायनिख्रुइ बांसिन जादों। बाबानि फावावसो बियो साबजागौमोन होननानै सानफ्लाङो। /\\\\<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 22\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: ಶುಷ್ಕ ತ್ವಚೆಗೆ ಸೂಕ್ತವಲ್ಲ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 23\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: என்னைப் பொறுத்தவரை Storytel இன் சிறந்த அம்சம் சிங்க்ரனைசேசன் (ஆஃப்லைன் பயன்பாடு). இது ஆஃப்லைனில் கூட கிடைக்கிறது. நான் விடுமுறைக்கு வெளியே செல்லும்போது அல்லது வார இறுதி நாட்களில் பூங்காவில் கூட புத்தகங்களைக் கேட்க முடியும்.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 24\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: വസ്തുവിലെ ഇന്റർഫേസ് തന്നെ കുഴപ്പമാണെന്ന് ഞാൻ കണ്ടെത്തി, നിങ്ങൾക്ക് ശരിയായ മിഡി ക്രമീകരണങ്ങൾ ആന്തരികമായി ക്രമീകരിക്കാൻ കഴിയില്ല.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 25\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਬੋਟ ਹੁਣ ਸਪੀਕਰ ਅਤੇ ਹੋਮ ਥੀਏਟਰ ਪ੍ਰਣਾਲੀਆਂ ਵਿੱਚ ਇੱਕ ਪ੍ਰਮੁੱਖ ਬ੍ਰਾਂਡ ਹੈ। ਇਹ ਬਲੂਟੁੱਥ, USB ਅਤੇ HDMI ਵਰਗੀਆਂ ਸਾਰੀਆਂ ਕਨੈਕਟੀਵਿਟੀ ਦੇ ਨਾਲ ਆਉਂਦਾ ਹੈ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 26\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: \"पेनची किंमत तशी परवडणारी आहे, परंतु त्याची वैशिष्ट्ये त्याच्या किंमतीला न्याय देत नाही. ग्रिपमुळे थोडे लिखाण केल्यावरही बोटांना घाम येतो आणि निब त्यांच्या इतर उत्पादनांच्या निबइतकी गुळगुळीत नाही. लिहिताना ते खडबडीत वाटते आणि कसातरीच आवाज करते.\"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 27\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: દરેક દ્રશ્યમાં જ્યાં માતાપિતા દેખાયા હતા, તેમને કોઈ અફસોસ નહોતો કે તેઓએ 2 ભાઈ-બહેનોને અલગ કર્યા જેઓ જોડિયા હતા અને તેમની કારકિર્દી/સુધારણા ખાતર તેમને આ વિશે જણાવ્યું ન હતું. માતા-પિતામાંથી કોઈએ એક વખત પણ બાળક કે જે તેમની સાથે રહેતો ન હતો તેને ફોન કર્યો ન હતો કે તેઓ શું કરી રહ્યા હતા તે અંગે આશ્ચર્ય થયું ન હતું.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 28\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: हा 400+ पारितोषिक-विजेत्या इन्स्टाग्राम स्टोरी टेम्पलेट्सचे कलेक्शन पुरवणारा आणि एडिटिंगचे कस्टमाईझ करता येणारे पर्याय असलेला फोटो एडिटर आणि व्हिडीओ मेकर आहे, अगदी मला जसा असायला हवा होता तसा!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 29\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: খারাপ ভয়েস কোয়ালিটির কারণে স্টোরিটেল শোনার সময় বিক্ষিপ্ত হওয়া এবং বিবরণগুলি মিস করা সহজ। প্রতিবার, বর্ণনাকারীর কোনওটির মড্যুলেশন দুর্বল হওয়ায় এটি শেষে একটি সমতল, নীরস, বিরক্তিকর টেক্সটের দিকে নিয়ে যায়।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 30\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: وائڈر ٹائرس کے مطابق ڈھالا جا سکتا ہے۔  بڑھتی بائیک اور سڑک کے لیے اچھا گیئر سسٹم ہے اور اپ گریڈ کیا جا سکتا ہے۔<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 31\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: ಇವುಗಳನ್ನು ಧೂಳು-ನಿರೋಧಕ ಎಂದು ಹೇಳಲಾಗುತ್ತದೆ, ಆದರೆ ಅವು ಹಾಗೆ ಕಾಣುವುದಿಲ್ಲ. ಅವು ಕೇವಲ ಹೊಳೆಯುವಂತೆ ಕಾಣುತ್ತವೆ ಆದರೆ ಬ್ಲೇಡ್\\u200cಗಳ ಮೇಲೆ ಧೂಳು ಆಗಾಗ್ಗೆ ಸಂಗ್ರಹವಾಗುತ್ತದೆ.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 32\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: ஜிப்பர் முழுமையாக மூடவில்லை. இது மேல் வெல்க்ரோ மூலம் மூட வேண்டியிருப்பதால் ஒவ்வொரு பக்கமும் 4 அங்குல இடைவெளி இருக்கிறது, சிறிய நாய்கள் இந்த வழியாக வெளியே வந்துவிடும்.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 33\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: पण या उत्पादनाच्या फ्लाईटच्या/टिकाऊपणाच्या बाबतीत तुम्ही चांगल्या दर्जाची अपेक्षा करू शकत नाही. हे शटल 10 मिनिटांच्या एकाच गेममध्ये तुटले, त्यांनी या उत्पादनासाठी माझे पैसे परत दिले पाहिजेत.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 34\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: صرف ایکشن کی خاطر وہ جتنا کر سکتے تھے کرنے کی کوشش کی لیکن قسمت سے نہیں ہوا۔ آپ کوئی جوش محسوس نہیں کریں گے... نہ کہانی کے ساتھ.. نہ ہی ایکشن کے ساتھ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 35\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: \"लगभग सभी मेट्रो शहरों में ऑनलाइन बुकिंग उपलब्ध नहीं है। \"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 36\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: অবজেক্টবোৰ প্ৰমাণিকভাৱে উপস্থাপন কৰিবলৈ উচ্চ ৰঙৰ ৰেণ্ডাৰিং সূচক ((CRI>96, TLCI≥98), প্ৰিমিয়াম এলুমিনিয়াম আধাৰিত নিৰ্মাণ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 37\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: सुगासेयावनो जिफोरनि गाबा खारो आरो जिफोरखौ फुद्ला नुयो आरो जियाबो कम बेसेननि सिनथेटिकनि।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 38\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: એક મજબૂત પ્રબળ સુગંધ ધરાવે છે જે લંબાય છે<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 39\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: പുസ്\\u200cതകങ്ങൾ എനിക്ക് വ്യക്തിപരമായി വളരെ വിശ്വാസ്യതയുള്ളതായി തോന്നിയില്ല. എന്റെ 11 വയസ്സുള്ള കുട്ടിക്ക് പല വസ്തുതകളും നേരത്തെ അറിയാമായിരുന്നതിനാൽ അവ വിദ്യാഭ്യാസപരമായ വളർച്ചയ്ക്ക് അനുയോജ്യമല്ല.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 40\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: કલાકારોની પસંદગી અને તેમનો અભિનય ઉત્કૃષ્ટ હતો!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 41\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: નવા નિશાળીયા માટે આ શ્રેષ્ઠ છે કારણ કે તે ખૂબ પ્રયત્નો કર્યા વિના સંતુલન પણ આપે છે.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 42\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: এইটো নতুন আৰম্ভ কৰাসকলৰ বাবে সৰ্বশ্ৰেষ্ঠ কিয়নো ই সহজে সন্তুলিত ভাৰসাম্য প্ৰদান কৰে।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 43\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: ആഖ്യാതാക്കളുടെ അഭിനയം മികച്ചതാണ്, അത് വായനക്കാരന്റെ മനസ്സിൽ കഥാപാത്രത്തിന്റെ ശക്തമായ പ്രതിച്ഛായ കെട്ടിപ്പടുക്കാൻ അവരെ സഹായിക്കുന്നു. പുസ്\\u200cതകങ്ങളിലെ കഥാപാത്രങ്ങളെ വളരെ നന്നായി വിവരിച്ചിരിക്കുന്നു, അവ നമ്മുടെ ജീവിതത്തിൽ നമുക്കറിയാവുന്നതുപോലെ തോന്നുന്നു.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 44\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: तेच जुने बॉडी शेमिंग करणारे विनोद, आपल्याला हसवण्याचा निष्फळ प्रयत्न करणारे. तुम्ही ट्रेलर बघितला असेल तर तुम्हाला 90% चित्रपट आधीच समजला असेल.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 45\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: खालच्या सप्तकातील सगळ्या कीज ना गुणगुणल्यासारखा आवाज आहे. परतावा उपलब्ध नाही.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 46\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: தரம் மோசம், சுய இரைச்சல் இருக்கிறது.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 47\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: মই এই এপ্পটো সুৰক্ষাৰ চিন্তাৰ কৰিয়েই বিলোপ কৰিছো। কোনো গোপনীয়তাৰ সুবিধা নাই, বাৰ্তাবোৰত এণ্ড-টু-এণ্ড এনক্ৰিপচন নাই বা প্লে ষ্টোৰত তেওঁলোকৰ বিৱৰণত সুৰক্ষাৰ বিষয়ে একো উল্লেখ নাই আৰু মই ব্যক্তিগতভাৱে ইয়াক সন্দেহজনক যেন অনুভৱ কৰো!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 48\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: एकसन सावथुन होननानै बुंदोंब्लाबो बे सावथुना दाबसेयावनो दिदोम थादों। स्टान्ट खालामनायाव आरो खमलायनायाव बारा जेबो गैया।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 49\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: இது ஆரம்பநிலையில் இருப்பவர்களுக்கு சிறந்தது, ஏனெனில் இது அதிக மெனக்கேடால் இல்லாமலேயே பேலன்ஸை கொடுக்கிறது.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 50\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: কেতিয়াবা অন কল সংযোগ বহুত নিম্ন হয়।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 51\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: \"स्लिपारा बांद्राय मोजां नङा। बिसोर मोनसे सिटाव सानै सानै मानसि बुकिं खालामो जाय सासे गेदेर आरो सासे गथʼनि थाखायलʼ गोरोबथाव।\"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 52\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: پنکھا باورچی خانے اور تمباکو نوشی کے علاقے جیسی جگہوں کے لیے بہت کارآمد ہے اور اس کی ہوا کی فراہمی کی رفتار مناسب ہے۔<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 53\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: ಫ್ಯಾನ್ ಅಡುಗೆಮನೆ ಮತ್ತು ಧೂಮಪಾನ ಪ್ರದೇಶದಂತಹ ಸ್ಥಳಗಳಿಗೆ ತುಂಬಾ ಪರಿಣಾಮಕಾರಿಯಾಗಿರುತ್ತದೆ ಮತ್ತು ಅದರ ಗಾಳಿಯ ವಿತರಣಾ ವೇಗವು ಸರಿಯಾಗಿದೆ.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 54\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: সকলো সংযোগ মোড যেনে তাঁৰযুক্ত, ব্লুটুথ, USB আৰু লগতে HDMI আছে। ই অডিঅ\\' আৰু ভিডিঅ\\' আউটপুট দুয়োটা চিংকত ৰাখে, ঠিক থিয়েটাৰবোৰৰ দৰে।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 55\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: मदर केअरच्या मॅट्रेसेस वजनाला अतिशय हलक्या आहेत आणि त्यांचा दर्जा हलका आहे, असे मला म्हणायचे नाही.  ही एक चांगली आणि मजबूत मॅट्रेस असून ती मला माझ्या बाळाला एका हातात धरूनही अॅडजेस्ट करता येते.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 56\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: दासिम खोनासंनायफोरनि गेजेराव गाज्रिसिन साउन्द गुन गोनां!!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 57\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: આ બોટનો સાઉન્ડબાર હજુ પણ તમામ સ્પીકર્સ માટે વાયર-કનેક્ટિવિટી છે. HDMI પોર્ટ બધા ઉપકરણો સાથે મેળ ખાતું નથી, તેથી તે ક્યારેક અચાનક ડિસ્કનેક્ટ થઈ જાય છે.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 58\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: गाने सुनने का मज़ेदार अनुभव!! हेडसेट के बिना भी बेहतरीन ऑडियो क्वालिटी।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 59\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: ಹಾಡುಗಳನ್ನು ಕೇಳುವುದೇ ಒಂದು ಆಹ್ಲಾದಕರ ಅನುಭವ!!  ಹೆಡ್\\u200cಸೆಟ್ ಇಲ್ಲದಿದ್ದರೂ ಸಹ ಆಡಿಯೋ ಗುಣಮಟ್ಟವು ನಿಜವಾಗಿಯೂ ಆಕರ್ಷಕವಾಗಿದೆ.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 60\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: ड्राई स्किन के लिए सूटेबल नहीं है।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 61\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: اب تک کی سب سے خراب آواز کا معیار!!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 62\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: मुझे लगता है कि इसका इंटरफ़ेस अपने आप में भद्दा है और आप आंतरिक रूप से सही मिडी सेटिंग्स को आसानी से एडजस्ट नहीं कर सकते।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 63\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: ഇതിന് വളരെ നേരിയ സുഗന്ധം ഉണ്ട്, അത് അധികസമയം നിലനിൽക്കില്ല. മണം കടുപ്പം കുറഞ്ഞതും ദൈനംദിന ഉപയോഗത്തിന് അനുയോജ്യവുമാണെങ്കിലും, ചൂടുള്ളതും ഈർപ്പമുള്ളതുമായ ദിവസങ്ങളിൽ ഇത് ഫലപ്രദമാവില്ല.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 64\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: భద్రతా ఆందోళనతో నేను ఈ యాప్\\u200cని తొలగించాను. గోప్యతా ఫీచర్ లేదు, సందేశాలకు ఎండ్-టు-ఎండ్ ఎన్ క్రిప్షన్ లేదు, లేదా ప్లే స్టోర్\\u200cలో వారి వివరణతో పేర్కొన్న భద్రత గురించి ఏమీ లేదు మరియు నేను వ్యక్తిగతంగా ఇది ఒక మోసపూరితమైనదిగా కనుగొన్నాను!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 65\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Marathi\\nText: यामुळे तुम्हाला ॲपसह काय शेअर करायचे आहे ते नियंत्रित करता येते. आणि ते खरोखर आपल्या खाजगी जागेत डोकावत नाहीत.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 66\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: மூட்டுகளை மறைக்கும் ரப்பர் கப் தளர்வாக இருக்கிறது, இதனால் மூட்டுகளில் எளிதில் தேய்மானம் ஏற்படும்.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 67\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: কুকুরের ট্রাভেল ফ্লাইট খাঁচায় টাই-ডাউন স্ট্র্যাপ হোল, বায়ুচলাচল তারের ভেন্ট এবং পোষা প্রাণীদের নিরাপদ এবং আরামদায়ক রাখার জন্য একটি উন্নত অভ্যন্তর রয়েছে। সহজ বহনের জন্য, একটি সহজ হ্যান্ডেল উপরে অবস্থিত। কুকুরকে অস্বস্তিকর বা ঠাসাঠাসি হওয়া ভাব থেকে রক্ষা করার জন্য এটিতে সঠিক বায়ুচলাচলের জন্য বায়ুচলাচল খোলা রয়েছে।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 68\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਵਾਸ਼ ਅਤੇ ਕੇਅਰ ਵਾਲਿਆਂ ਨੇ ਲਿਖਿਆ ਤਾਂ ਹੋਇਆ ਹੈ ਕਿ ਇਨ੍ਹਾਂ ਨੂੰ ਧੋਇਆ ਜਾ ਸਕਦਾ ਹੈ ਪਰ ਮੈਂ ਸਵਿੰਗ ਤੋਂ ਸਵਿੰਗ ਕੋਟ ਨੂੰ ਕਿਵੇਂ ਹਟਾ ਸਕਦੀ ਹਾਂ। ਮੈਂ ਬਹੁਤ ਨਿਰਾਸ਼ ਮਹਿਸੂਸ ਕਰਦੀ ਹਾਂ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 69\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: \"ପେନ୍ ଜଣଙ୍କ ପକେଟକୁ ଭଲ ଲାଗେ, କିନ୍ତୁ ସ୍ପେକ୍ସ ଏହାର ମୂଲ୍ୟକୁ ଯଥାର୍ଥ କରେ ନାହିଁ | ଗ୍ରିପ୍ ଅଧିକାଂଶ ଲେଖକଙ୍କ ଆଙ୍ଗୁଠିକୁ ଝାଳୁଆ କରେ, ଏବଂ ନିବ୍ ସେମାନଙ୍କର ଅନ୍ୟ ଉତ୍ପାଦ ପରି ସୁଗମ ନୁହେଁ | ଏହା ଦାନାଯୁକ୍ତ ଅନୁଭବ ଦିଏ ଏବଂ ଲେଖିବା ସମୟରେ ଏକ ଅପ୍ରୀତିକର ଶବ୍ଦ କରେ | \"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 70\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: जोबोद रोमैदु फिथाइनि मोदोमनायजों बेयो गोख्रों माइसराइजिं होयो।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 71\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਜ਼ਿਆਦਾਤਰ ਕਹਾਣੀਆਂ ਵਿੱਚ ਬਹੁਤੀ ਸਮਝ ਨਹੀਂ ਹੈ ਅਤੇ ਮੇਰੀ ਅੱਠ ਸਾਲ ਦੀ ਬੱਚੀ ਦੀ ਪੜ੍ਹਨ ਦੀ ਜ਼ਰੂਰਤ ਨੂੰ ਪੂਰਾ ਕਰਨ ਵਿੱਚ ਬੁਰੀ ਤਰ੍ਹਾਂ ਅਸਫਲ ਰਹੀਆਂ ਹਨ।  ਮੈਂ ਉਹਨਾਂ ਲੋਕਾਂ ਨੂੰ ਇਸਦੀ ਸਿਫ਼ਾਰਸ਼ ਨਹੀਂ ਕਰਦਾ ਜੋ ਇਸ ਕਿਤਾਬ ਦੁਆਰਾ ਵਿੱਦਿਅਕ ਵਿਕਾਸ ਦੀ ਭਾਲ ਕਰ ਰਹੇ ਹਨ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 72\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: 1120 mAh, അമിത ചാർജിംഗിൽ നിന്നുള്ള പരിരക്ഷ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 73\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: বটলটো আচল নাছিল। যেতিয়া মই এইটো পাইছিলো তেতিয়া সেইটো ইতিমধ্যে ক্ষতিগ্ৰস্ত হৈছিল। মোৰ টকা ঘূৰাই বিচাৰো!!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 74\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: বন্ধু, পরিবার, এবং একই আগ্রহের গ্রূপের সাথে ভালো সংযোগের জন্য এটি খুবই ভালো এটি ব্যবহার করাও সহজ, তাছাড়াও এর মধ্যে রয়েছে: সমস্ত পরিচিতি বনাম ঘনিষ্ঠ বন্ধুদের জন্য উৎসর্গীকৃত ফিড; ব্যক্তিগত এবং ওপেন গ্রুপ;<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 75\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Tamil\\nText: மதர் கேர் மெத்தைகள் மிகவும் எடை குறைவாக இருக்கின்றன, அதற்காக அவற்றின் தரம் குறைவாக இருக்கிறது என்று பொருளல்ல. என் குழந்தையை ஒரு கையில் வைத்துக்கொண்டு என்னால் அட்ஜஸ்ட் செய்ய முடிகிற நல்ல, கெட்டியான மெத்தை.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 76\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: వీరు తమ ప్రపంచ స్థాయి ఇంజనీరింగ్, హై-స్పీడ్ సామర్ధ్యం, ప్రత్యేక శైలి మరియు ప్రపంచవ్యాప్త డీలర్\\u200cషిప్ మద్దతుకు ప్రసిద్ధి గాంచారు.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 77\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bengali\\nText: এতে থাকা ক্যারামেল রঙ (সালফাইট অ্যামোনিয়া ক্যারামেল) বেশি পরিমাণে খেলে অ্যালার্জি হতে পারে।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 78\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Assamese\\nText: ব্লুটুথে টিথাৰ কৰা ডিভাইচৰ বাহিৰে কোনো নতুন ডিভাইচ সমৰ্থন নকৰে। নতুন ডিভাইচ এটা সংযোগহীন আৰু সংযোগ কৰিবলৈ যথেষ্ট সময় লাগে, যিটো সদায় এক বিৰক্তিকৰ অভিজ্ঞতা।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 79\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: ମୁଁ ଏହି ପୁସ୍ତକକୁ 5 ତାରକା ସମୀକ୍ଷା ଦେଇଥିଲି କାରଣ ଏହା ଏକ ଚମତ୍କାର କାହାଣୀରେ ପରିପୂର୍ଣ୍ଣ ଯାହା କେବଳ ସମସ୍ତ ମିଠା ପ୍ରତି ଭଲପାଉଥିବା ଛୋଟ ପିଲାଙ୍କ ମନରେ ରହିପାରେ | ଏହା ଚମତ୍କାର, ଆକର୍ଷଣୀୟ ଚିତ୍ର ସହିତ ଆସିଥାଏ ଯାହା କୌଣସି ଛୋଟ ପିଲାକୁ ଚିତ୍ର ଦ୍ୱାରା କାହାଣୀ ପଢ଼ିବାକୁ ଉତ୍ସାହିତ ରଖିବ |<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 80\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਇਹ ਬਾਡੀ ਵਾਸ਼ ਮੁਲਾਇਮ ਅਤੇ ਨਮੀ ਵਾਲੀ ਚਮੜੀ ਦਿੰਦਾ ਹੈ। ਪੈਕੇਜਿੰਗ ਯਾਤਰਾ ਅਨੁਕੂਲ ਹੈ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 81\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Gujarati\\nText: રેઇન કવર અને એડજસ્ટેબલ સ્ટ્રેપ સાથે, અંદરથી સારી રીતે ગાદીવાળું.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 82\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਐਂਟਰੀ ਮੁਫ਼ਤ ਹੈ ਅਤੇ ਕਿਉਂਕਿ ਇਹ ਸਿਰਫ਼ ਸੋਸਾਇਟੀ ਦੇ ਮੈਂਬਰਾਂ ਲਈ ਹੈ, ਇਸ ਲਈ ਇੱਥੇ ਵਧੇਰੇ ਸੁਰੱਖਿਅਤ ਮਹਿਸੂਸ ਹੁੰਦਾ ਹੈ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 83\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: వేసవి కాలానికి అధికంగా పొడిబారిన చర్మానికి తగినది కాదు, సువాసన ఎక్కువ కాలం నిలవదు<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 84\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: रेजें फेन आरो गेदेर गुसु खालामग्रा टेंकि। बेयो कुलारखौ गोबाव सम मोजाङै आरो बन्दʼ जाहोआलासे लाखियो।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 85\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Urdu\\nText: رنبیر کی اداکاری صرف مافوق الفطرت ہے۔ ایسا لگتا ہے کہ وہ بابا کے کردار کے لیے قدرتی طور پر فٹ ہے۔ /\\\\<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 86\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Kannada\\nText: ಆಟಮ್\\u200cಬರ್ಗ್\\u200cನ ಪೀಠದ ಅಭಿಮಾನಿಗಳು ಕಡಿಮೆ ದಕ್ಷತೆಯ ಮೋಟಾರು ಅಳವಡಿಸಲಾಗಿದೆ. ಫ್ಯಾನ್ ವಿಭಿನ್ನ ವೈಶಿಷ್ಟ್ಯಗಳನ್ನು ಹೊಂದಿದ್ದರೂ ಸಹ ಗಾಳಿಯ ವಿತರಣಾ ವೇಗವು ಕೊರತೆಯಿದೆ.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 87\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Hindi\\nText: \"इस चेयर में बहुत ही खराब और कम कुशनिंग और लंबर स्पोर्ट है। इसके अलावा, इसमें कोई इनर थाई सपोर्ट, और बैक या नेक रिक्लाइन नहीं है।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 88\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਟੀ ਰਬੜ ਦੇ ਕੱਪ ਜੋ ਜੋੜਾਂ ਨੂੰ ਢੱਕਦੇ ਹਨ ਢਿੱਲੇ ਸਨ ਅਤੇ ਜੋੜਾਂ ਦੇ ਜਲਦੀ ਖ਼ਰਾਬ ਹੋਣ ਦਾ ਖ਼ਤਰਾ ਰਹਿੰਦਾ ਹੈ।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 89\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: କିନ୍ତୁ ଏହି ଉତ୍ପାଦ ପାଇଁ ଉଡ଼ାଣ / ସ୍ଥାୟୀତ୍ୱ ଦୃଷ୍ଟିରୁ ଆପଣ ଗୁଣବତ୍ତା ଆଶା କରିପାରିବେ ନାହିଁ | ଏହି ସଟଲ୍ 10 ମିନିଟର ଗୋଟିଏ ଖେଳରେ ଭାଙ୍ଗିଗଲା, ସେମାନେ ମୋ ଟଙ୍କା ଫେରସ୍ତ କରିବା ଉଚିତ୍ |<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 90\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Punjabi\\nText: ਫਿਲਟਰ ਆਡੀਓ ਗੁਣਵੱਤਾ ਨੂੰ ਬਹੁਤ ਘਟਾਉਂਦਾ ਹੈ<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 91\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: ସବୁଠୁ ଖରାପ ଧ୍ୱନି କ୍ୱାଲିଟି !!<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 92\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: ଏହା ଏକ ଚମତ୍କାର ବୈଶିଷ୍ଟ୍ୟ ଯାହା ଉତ୍ପାଦର କାର୍ଯ୍ୟଦକ୍ଷତାକୁ ଯଥେଷ୍ଟ ବୃଦ୍ଧି କରିଥାଏ |<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 93\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: ఉషా నుండి ఈ పర్సనల్ ఎయిర్ కూలర్ చాలా మృదువైన బ్లోయర్\\u200cతో వస్తుంది, మీరు దీనిని కూలర్ వలే కాకుండా ఫ్యాన్\\u200cలా అనుభూతి చెందుతారు. ధ్వని స్థాయి చాలా తక్కువగా ఉంటుంది.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 94\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: “ଟ୍ରେନରେ ବୁଲୁଥିବା ବିକ୍ରେତାମାନେ ଏକ ବଡ଼ ଅସନ୍ତୋଷ”<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 95\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Telugu\\nText: దర్శకత్వం చాలా బాగుంది, మరియు నటన కూడా బాగుంది, అద్భుతమైన సినిమాటోగ్రఫీ. కథలో అనేక మలుపులు ఉన్యి.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 96\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Odia\\nText: ଏହା ଭଲ କ୍ୱାଲିଟିର ଗଦି ସହିତ ଭଲ ପ୍ୟାଡେଡ୍ ହୋଇଛି |<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 97\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: അടുത്തിടെ ഞാൻ \"Unfold\" എന്നതിൽ നിന്ന് ഒരു ടെംപ്ലേറ്റ് വാങ്ങി, പക്ഷേ അത് ആക്\\u200cസസ് ചെയ്യാനോ എന്റെ എഡിറ്റിംഗ് പേജ് കാണാനോ കഴിഞ്ഞില്ല. ഇത് തികച്ചും അലോസരപ്പെടുത്തുന്നതാണ്, ബാങ്ക് അക്കൗണ്ടിൽ നിന്ന് പണം കിഴിവ് ചെയ്തു, ടെംപ്ലേറ്റ് ഡോൺലോഡ് ചെയ്തു എന്ന് കാണിക്കുന്നു ഡൗൺലോഡ് ചെയ്\\u200cതു, പക്ഷേ എഡിറ്റിംഗ് മോഡിൽ അത് പ്രതിഫലിക്കുന്നില്ല.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Negative\n",
      "--------------\n",
      "Instance 98\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Malayalam\\nText: \"സംസ്ഥാനത്ത് നല്ല ബന്ധമാണുള്ളത്. നിങ്ങൾക്ക് സംസ്ഥാനത്തെ മിക്കവാറും എല്ലാ വലിയ നഗരങ്ങളിലേക്കും ചില അന്തർസംസ്ഥാന ലക്ഷ്യസ്ഥാനങ്ങളിലേക്കും അവരുടെ സേവനങ്ങൾ ഉപയോഗിച്ച് പോകാം.\"<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n",
      "--------------\n",
      "Instance 99\n",
      "--------------\n",
      "checking for {'text': '<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\nYou are a highly accurate MULTILINGUAL sentiment analysis bot, specializing in Indian Languages. Your sole purpose is to analyze the sentiment of user-provided text (along with the language) and output a JSON object with a single field: \"sentiment\". The value of \"sentiment\" MUST be either \"Positive\" or \"Negative\" and nothing else. There\\'s no options such as \"Neutral\" or anything else. It\\'s only either \"Positive\" or \"Negative\" Do not include any other text or explanations in your output. Adhere strictly to the JSON format. The input can be in any language. Incorrectly formatter or explainer outputs will be considered a failure and you will be heavily penalized for it. some example inputs and outputs are given, you can follow the same instructions.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nExamples:\\n1. Language: Bodo\\nText: जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जायगायावनो सोफानांगौ। फेन्दा फिथाइ एबा जान्जिखौ दोननो गान्दु गैया।\\nOutput: {\"sentiment\": \"Negative\"}\\n\\n2. Language: Telugu\\nText: కొన్ని మంచి బ్యాండ్\\u200cలు ప్లే చేయడం మరియు లైవ్ ప్రదర్శలు ఇవ్వడం వల్ల ఆంబియెన్స్ అద్భుతంగా ఉంటుంది, అలానే ఫుడ్ చాలా బాగుంటుంది. ఆల్కహాల్ కలెక్షన్ కూడా చాలా బాగుంటుంది.\\nOutput: {\"sentiment\": \"Positive\"}\\n\\n3. Language: Tamil\\nText: கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும் அவர்களுடைய நடிப்பும் சிறப்பாக இருந்தன. ஜாலியாக இருந்தது அதே நேரத்தில் உணர்ச்சிகளின் கலவையாக இருந்தது.\\nOutput: {\"sentiment\": \"Positive\"}\\nCurrent Input:\\nLanguage: Bodo\\nText: गोबां बोसोर सिगांनिफ्रायनो आं बेखौ मोजां मोनबोदों आरो बेयो गावनि मासिखौ दाबो लाखिना दं। बेयो एलकहल गैयि आरो देहानि मोनामनायखौ हमथाना लाखियो।<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>'}\n",
      "\tPredicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "outlist  = eval_model(model, test_dataset_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e163b423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:20:53.409809Z",
     "iopub.status.busy": "2025-02-18T03:20:53.409326Z",
     "iopub.status.idle": "2025-02-18T03:20:53.414237Z",
     "shell.execute_reply": "2025-02-18T03:20:53.413490Z"
    },
    "papermill": {
     "duration": 0.073137,
     "end_time": "2025-02-18T03:20:53.415611",
     "exception": false,
     "start_time": "2025-02-18T03:20:53.342474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_submission(outlist: list):\n",
    "    submission = pd.DataFrame(columns=['ID', 'label'])\n",
    "    submission['ID'] = [i for i in range(1, len(outlist)+1)]\n",
    "    submission['label'] = outlist\n",
    "\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e68544e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T03:20:53.549798Z",
     "iopub.status.busy": "2025-02-18T03:20:53.549474Z",
     "iopub.status.idle": "2025-02-18T03:20:53.613304Z",
     "shell.execute_reply": "2025-02-18T03:20:53.612462Z"
    },
    "papermill": {
     "duration": 0.130998,
     "end_time": "2025-02-18T03:20:53.614629",
     "exception": false,
     "start_time": "2025-02-18T03:20:53.483631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission(outlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b05dfb",
   "metadata": {
    "papermill": {
     "duration": 0.067019,
     "end_time": "2025-02-18T03:20:53.748589",
     "exception": false,
     "start_time": "2025-02-18T03:20:53.681570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11098970,
     "sourceId": 93282,
     "sourceType": "competition"
    },
    {
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1369.043454,
   "end_time": "2025-02-18T03:20:57.403696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-18T02:58:08.360242",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00bb9155f5ef4ed29ab1875cabfc8157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6273c0cb7d524a0297cbf478f18d863b",
        "IPY_MODEL_42b10de410644a948c470bc1fac52631",
        "IPY_MODEL_d447131e13fa43a7832f9da0caffa497"
       ],
       "layout": "IPY_MODEL_f3c4da77a601493e9ce5886f37b5ad8b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "03432afc7cdb42ee8c2b5406347f1cad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "10e09e5e15b54d699166e1c4fad361cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "129eb37e80054e2da2f18aca80ca7665": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d164037abe944fd885717975948c491": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d87427ee65246ac862bbf4f80f2595c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "27cb043367254c6fba190cd39e571f43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2c67b6352cf342ed9458d0d576a40b4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a177450ec0e4484eaf27679564dfe795",
        "IPY_MODEL_f5366af3415048e697f473a1008f0362",
        "IPY_MODEL_65380ad4145f430a8c799f312d60b1e0"
       ],
       "layout": "IPY_MODEL_03432afc7cdb42ee8c2b5406347f1cad",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2c9334749cbf45289e312b78ac4f0418": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "312300e6cda24013b6b152bd3ca031ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3382c6bef94f43fa8b643dfb76970b3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35dbe90e2b8d4914bcb29495394e9989": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42b10de410644a948c470bc1fac52631": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8dbaa50609884d0996b0338b2d6b26df",
       "max": 1000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_615ea3c3fd8240348a5048f2d6799bad",
       "tabbable": null,
       "tooltip": null,
       "value": 1000.0
      }
     },
     "4aab655cfbff4c4fa2e66eb7e6e26176": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "517be518f8914e2abef7e65d3324834c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4aab655cfbff4c4fa2e66eb7e6e26176",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e91b03b7e3544436806aa023edc0044e",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     },
     "552db704cd0a4ab19471c1fe77d19337": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f9a4da7e9094aad9cb8757adc7d135f",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e32956023c554d6f858e8faec970f502",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "5742670c9e0a4dc9a7ae06c60264caa5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57bdddb5a3c54eca88503356e3c86a14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10e09e5e15b54d699166e1c4fad361cc",
       "placeholder": "​",
       "style": "IPY_MODEL_9f858a3dc3c34b6fa96e657ddb329745",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "5d0d4c38f6a944238e97d70c900dcbff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6096339559994e70bc5e9b44e8c36769": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "615ea3c3fd8240348a5048f2d6799bad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6273c0cb7d524a0297cbf478f18d863b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f8fb38e8d5064ec49c86fa4e643bb5c6",
       "placeholder": "​",
       "style": "IPY_MODEL_27cb043367254c6fba190cd39e571f43",
       "tabbable": null,
       "tooltip": null,
       "value": "Tokenizing train dataset (num_proc=2): 100%"
      }
     },
     "63091c2daaf24d9c80e3d11dc8a0fff5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "64fd5fb45d6f4c09a3ebacf7adaacc0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65380ad4145f430a8c799f312d60b1e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_86f1ad165d834a8ea69fcc6eddef530c",
       "placeholder": "​",
       "style": "IPY_MODEL_2c9334749cbf45289e312b78ac4f0418",
       "tabbable": null,
       "tooltip": null,
       "value": " 1000/1000 [00:01&lt;00:00, 1370.59 examples/s]"
      }
     },
     "6ece3b10512a4d7d85d611abec1cc912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6096339559994e70bc5e9b44e8c36769",
       "placeholder": "​",
       "style": "IPY_MODEL_89ffefc01d2d4a949f6832b9395e2331",
       "tabbable": null,
       "tooltip": null,
       "value": " 1000/1000 [00:00&lt;00:00, 1142.03 examples/s]"
      }
     },
     "7024cd51e10747959013649f0917ce42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "725e5aa05d594a6f8e1183ecd63692ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "763171231cda4efbb4d7d7819b724817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ea286264dbe47e6a87e31d5da3b11c8",
       "max": 1000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_725e5aa05d594a6f8e1183ecd63692ec",
       "tabbable": null,
       "tooltip": null,
       "value": 1000.0
      }
     },
     "7ae4a430f46f4a57b26d755d14a8fb69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e98a6c0d7cd4bf4aea01143c07f1cd8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_57bdddb5a3c54eca88503356e3c86a14",
        "IPY_MODEL_517be518f8914e2abef7e65d3324834c",
        "IPY_MODEL_ba77f5cb5c9043189d1a1ab78acd7412"
       ],
       "layout": "IPY_MODEL_a9321407c93f4a02a3217dd414b784a6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8420004e18624f339d72dd20a06ab10b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64fd5fb45d6f4c09a3ebacf7adaacc0f",
       "placeholder": "​",
       "style": "IPY_MODEL_e7e44d38c3bf472986fca58a562e52cd",
       "tabbable": null,
       "tooltip": null,
       "value": " 1000/1000 [00:01&lt;00:00, 728.49 examples/s]"
      }
     },
     "85f56107976445c9b8f3c103643ad325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "86f1ad165d834a8ea69fcc6eddef530c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "878e7b0feaa44871ab61e34a9d96e771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "87da073b716248b89f8c0c1efbe92a2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_efafef2064a9468f9af263ac92c72a68",
        "IPY_MODEL_bd5cf673c3bb42cfbbe8b328c52c2220",
        "IPY_MODEL_6ece3b10512a4d7d85d611abec1cc912"
       ],
       "layout": "IPY_MODEL_129eb37e80054e2da2f18aca80ca7665",
       "tabbable": null,
       "tooltip": null
      }
     },
     "89ffefc01d2d4a949f6832b9395e2331": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8a572b749a054bb186263008afd1ec39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8dbaa50609884d0996b0338b2d6b26df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "932895c873494a028325a4e8cad9bf20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "966417d5afd24e1ea0862c9c0bf83ebc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ea286264dbe47e6a87e31d5da3b11c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f858a3dc3c34b6fa96e657ddb329745": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9f9a4da7e9094aad9cb8757adc7d135f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a177450ec0e4484eaf27679564dfe795": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cda235f5c48044bb9555d3fca4688109",
       "placeholder": "​",
       "style": "IPY_MODEL_cb31556774874d1d939d4eaee525c341",
       "tabbable": null,
       "tooltip": null,
       "value": "Tokenizing train dataset (num_proc=2): 100%"
      }
     },
     "a2948a3e07664367b4ecc147fb0e9472": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a4965cd3cf654ed3acc04defcdfc8478": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8a572b749a054bb186263008afd1ec39",
       "placeholder": "​",
       "style": "IPY_MODEL_85f56107976445c9b8f3c103643ad325",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "a9321407c93f4a02a3217dd414b784a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b651f9b4344048298d99ed7bdfbb8358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f908aac2754e44668fd7ca09644007ee",
        "IPY_MODEL_552db704cd0a4ab19471c1fe77d19337",
        "IPY_MODEL_cb468375e3284599a06cc98f6b555ed0"
       ],
       "layout": "IPY_MODEL_966417d5afd24e1ea0862c9c0bf83ebc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b872b575087e4775afe29a53d921b2e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4965cd3cf654ed3acc04defcdfc8478",
        "IPY_MODEL_763171231cda4efbb4d7d7819b724817",
        "IPY_MODEL_d6400751a73a467c84ec5e4c2db14b14"
       ],
       "layout": "IPY_MODEL_7024cd51e10747959013649f0917ce42",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ba77f5cb5c9043189d1a1ab78acd7412": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d0d4c38f6a944238e97d70c900dcbff",
       "placeholder": "​",
       "style": "IPY_MODEL_63091c2daaf24d9c80e3d11dc8a0fff5",
       "tabbable": null,
       "tooltip": null,
       "value": " 100/100 [00:00&lt;00:00, 3627.51 examples/s]"
      }
     },
     "bd5cf673c3bb42cfbbe8b328c52c2220": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7ae4a430f46f4a57b26d755d14a8fb69",
       "max": 1000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_878e7b0feaa44871ab61e34a9d96e771",
       "tabbable": null,
       "tooltip": null,
       "value": 1000.0
      }
     },
     "c8a83164b9cb44c7afc10ffa80b52e5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb31556774874d1d939d4eaee525c341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb468375e3284599a06cc98f6b555ed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e9020e373cda47c5bd023c6dd164c24b",
       "placeholder": "​",
       "style": "IPY_MODEL_1d87427ee65246ac862bbf4f80f2595c",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [01:22&lt;00:00, 17.85s/it]"
      }
     },
     "cb962edb0529489387a7f661a58399d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cda235f5c48044bb9555d3fca4688109": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf19f020f5cf4bcfbb8feb9b8e08d511": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d447131e13fa43a7832f9da0caffa497": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d164037abe944fd885717975948c491",
       "placeholder": "​",
       "style": "IPY_MODEL_e25aa30694b14523859712bc29702088",
       "tabbable": null,
       "tooltip": null,
       "value": " 1000/1000 [00:02&lt;00:00, 764.62 examples/s]"
      }
     },
     "d6400751a73a467c84ec5e4c2db14b14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c8a83164b9cb44c7afc10ffa80b52e5a",
       "placeholder": "​",
       "style": "IPY_MODEL_35dbe90e2b8d4914bcb29495394e9989",
       "tabbable": null,
       "tooltip": null,
       "value": " 1000/1000 [00:00&lt;00:00, 9312.52 examples/s]"
      }
     },
     "da49d9586d7b437eb0b3b595a905035e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd093902893d48ddb78bc6b50a69889b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e25aa30694b14523859712bc29702088": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e32956023c554d6f858e8faec970f502": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e4e88cfc1060412b9e2f05e64afb3b6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5742670c9e0a4dc9a7ae06c60264caa5",
       "placeholder": "​",
       "style": "IPY_MODEL_cf19f020f5cf4bcfbb8feb9b8e08d511",
       "tabbable": null,
       "tooltip": null,
       "value": "Applying chat template to train dataset (num_proc=2): 100%"
      }
     },
     "e7e44d38c3bf472986fca58a562e52cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e9020e373cda47c5bd023c6dd164c24b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e91b03b7e3544436806aa023edc0044e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ec5f5ef41a4a44ee8c10c15b9c179f1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4d4986b19d34ed9b7bba0cbc97a8f84",
       "max": 1000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_312300e6cda24013b6b152bd3ca031ad",
       "tabbable": null,
       "tooltip": null,
       "value": 1000.0
      }
     },
     "efafef2064a9468f9af263ac92c72a68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb962edb0529489387a7f661a58399d7",
       "placeholder": "​",
       "style": "IPY_MODEL_f764afbfaad84c879fcfe60f7a126931",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "f3c4da77a601493e9ce5886f37b5ad8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4d4986b19d34ed9b7bba0cbc97a8f84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5366af3415048e697f473a1008f0362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3382c6bef94f43fa8b643dfb76970b3c",
       "max": 1000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2948a3e07664367b4ecc147fb0e9472",
       "tabbable": null,
       "tooltip": null,
       "value": 1000.0
      }
     },
     "f764afbfaad84c879fcfe60f7a126931": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8fb38e8d5064ec49c86fa4e643bb5c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f908aac2754e44668fd7ca09644007ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd093902893d48ddb78bc6b50a69889b",
       "placeholder": "​",
       "style": "IPY_MODEL_932895c873494a028325a4e8cad9bf20",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "f9afb39194cb4c029290ac78f25f05de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4e88cfc1060412b9e2f05e64afb3b6e",
        "IPY_MODEL_ec5f5ef41a4a44ee8c10c15b9c179f1b",
        "IPY_MODEL_8420004e18624f339d72dd20a06ab10b"
       ],
       "layout": "IPY_MODEL_da49d9586d7b437eb0b3b595a905035e",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
