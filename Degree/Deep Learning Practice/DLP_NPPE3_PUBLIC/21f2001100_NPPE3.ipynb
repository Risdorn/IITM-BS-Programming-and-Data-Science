{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97753,"databundleVersionId":11639668,"sourceType":"competition"},{"sourceId":11301515,"sourceType":"datasetVersion","datasetId":7067698}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:22.800533Z","iopub.execute_input":"2025-04-07T11:30:22.800870Z","iopub.status.idle":"2025-04-07T11:30:22.804772Z","shell.execute_reply.started":"2025-04-07T11:30:22.800842Z","shell.execute_reply":"2025-04-07T11:30:22.803751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install git+https://github.com/XPixelGroup/BasicSR.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:22.805759Z","iopub.execute_input":"2025-04-07T11:30:22.805975Z","iopub.status.idle":"2025-04-07T11:30:27.837954Z","shell.execute_reply.started":"2025-04-07T11:30:22.805957Z","shell.execute_reply":"2025-04-07T11:30:27.836971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from basicsr.archs.rrdbnet_arch import RRDBNet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:27.839688Z","iopub.execute_input":"2025-04-07T11:30:27.839935Z","iopub.status.idle":"2025-04-07T11:30:27.843572Z","shell.execute_reply.started":"2025-04-07T11:30:27.839913Z","shell.execute_reply":"2025-04-07T11:30:27.842884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install einops timm opencv-python pytorch-lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:27.844780Z","iopub.execute_input":"2025-04-07T11:30:27.845081Z","iopub.status.idle":"2025-04-07T11:30:31.327224Z","shell.execute_reply.started":"2025-04-07T11:30:27.845052Z","shell.execute_reply":"2025-04-07T11:30:31.326175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import ToTensor\nfrom torch import nn, optim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom basicsr.archs.rrdbnet_arch import RRDBNet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.328342Z","iopub.execute_input":"2025-04-07T11:30:31.328706Z","iopub.status.idle":"2025-04-07T11:30:31.333470Z","shell.execute_reply.started":"2025-04-07T11:30:31.328670Z","shell.execute_reply":"2025-04-07T11:30:31.332696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.334382Z","iopub.execute_input":"2025-04-07T11:30:31.334635Z","iopub.status.idle":"2025-04-07T11:30:31.350756Z","shell.execute_reply.started":"2025-04-07T11:30:31.334605Z","shell.execute_reply":"2025-04-07T11:30:31.349982Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Custom Dataset for Paired Image Super-Resolution","metadata":{}},{"cell_type":"code","source":"class PairedImageDataset(Dataset):\n    def __init__(self, low_dir, high_dir):\n        self.low_dir = low_dir\n        self.high_dir = high_dir\n        self.filenames = sorted(os.listdir(low_dir))\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        filename = self.filenames[idx]\n        low = cv2.imread(os.path.join(self.low_dir, filename))[:, :, ::-1]\n        high = cv2.imread(os.path.join(self.high_dir, filename))[:, :, ::-1]\n        low = (low / 255.0).astype(np.float32)\n        high = (high / 255.0).astype(np.float32)\n        return ToTensor()(low), ToTensor()(high)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.351489Z","iopub.execute_input":"2025-04-07T11:30:31.351681Z","iopub.status.idle":"2025-04-07T11:30:31.367408Z","shell.execute_reply.started":"2025-04-07T11:30:31.351665Z","shell.execute_reply":"2025-04-07T11:30:31.366660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torch.utils.data import Dataset\n# from torchvision.transforms import ToTensor\n# import cv2\n\n\n# class PairedImageDataset(Dataset):\n#     def __init__(self, low_dir, high_dir):\n#         self.low_dir = low_dir\n#         self.high_dir = high_dir\n#         self.filenames = sorted(os.listdir(low_dir))\n\n#     def __len__(self):\n#         return len(self.filenames)\n\n#     def __getitem__(self, idx):\n#         filename = self.filenames[idx]\n\n#         low_path = os.path.join(self.low_dir, filename)\n#         high_path = os.path.join(self.high_dir, filename)\n\n#         # Load with cv2 and ensure it loaded correctly\n#         low = cv2.imread(low_path)\n#         high = cv2.imread(high_path)\n\n#         if low is None or high is None:\n#             raise FileNotFoundError(f\"Missing file: {filename}\")\n\n#         # Convert BGR to RGB\n#         low = cv2.cvtColor(low, cv2.COLOR_BGR2RGB)\n#         high = cv2.cvtColor(high, cv2.COLOR_BGR2RGB)\n\n#         # Normalize to [0, 1]\n#         low = (low / 255.0).astype(np.float32)\n#         high = (high / 255.0).astype(np.float32)\n\n#         # Convert to torch.Tensor\n#         return ToTensor()(low), ToTensor()(high)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.368208Z","iopub.execute_input":"2025-04-07T11:30:31.368392Z","iopub.status.idle":"2025-04-07T11:30:31.380655Z","shell.execute_reply.started":"2025-04-07T11:30:31.368376Z","shell.execute_reply":"2025-04-07T11:30:31.379992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torchvision.transforms as T\n# from torchvision.transforms import ToTensor, ToPILImage\n\n# # Define your transform pipeline\n# transform = T.Compose([\n#     T.ToPILImage(),\n#     T.RandomHorizontalFlip(),\n#     T.RandomVerticalFlip(),\n#     T.RandomRotation(10),\n#     T.ToTensor()\n# ])\n\n# class PairedImageDataset(Dataset):\n#     def __init__(self, low_dir, high_dir, transform=None):\n#         self.low_dir = low_dir\n#         self.high_dir = high_dir\n#         self.filenames = sorted(os.listdir(low_dir))\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.filenames)\n\n#     def __getitem__(self, idx):\n#         filename = self.filenames[idx]\n        \n#         # Load and normalize\n#         low = cv2.imread(os.path.join(self.low_dir, filename))[:, :, ::-1]\n#         high = cv2.imread(os.path.join(self.high_dir, filename))[:, :, ::-1]\n\n#         low = (low * 255.0).clip(0, 255).astype(np.uint8)  # Back to uint8 for PIL\n#         high = (high * 255.0).clip(0, 255).astype(np.uint8)\n\n#         if self.transform:\n#             # Ensure both images undergo the same random transformation\n#             seed = np.random.randint(99999)\n#             torch.manual_seed(seed)\n#             low = self.transform(low)\n#             torch.manual_seed(seed)\n#             high = self.transform(high)\n#         else:\n#             low = ToTensor()(low.astype(np.float32) / 255.0)\n#             high = ToTensor()(high.astype(np.float32) / 255.0)\n\n#         return low, high\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.382917Z","iopub.execute_input":"2025-04-07T11:30:31.383142Z","iopub.status.idle":"2025-04-07T11:30:31.399700Z","shell.execute_reply.started":"2025-04-07T11:30:31.383124Z","shell.execute_reply":"2025-04-07T11:30:31.398906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Loading Pretrained Real-ESRGAN Model","metadata":{}},{"cell_type":"code","source":"def load_esrgan_model():\n    model_path = '/kaggle/input/real-esrgan-model/RealESRGAN_x4plus.pth'\n    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n    state_dict = torch.load(model_path, map_location='cpu')\n    if 'params_ema' in state_dict:\n        state_dict = state_dict['params_ema']\n    model.load_state_dict(state_dict, strict=True)\n    torch.cuda.empty_cache()\n    model.to(device).eval()\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.401029Z","iopub.execute_input":"2025-04-07T11:30:31.401301Z","iopub.status.idle":"2025-04-07T11:30:31.417431Z","shell.execute_reply.started":"2025-04-07T11:30:31.401280Z","shell.execute_reply":"2025-04-07T11:30:31.416798Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  Preprocessing and Inference Image Conversion","metadata":{}},{"cell_type":"code","source":"# Function to upscale a single image using the model\n\ndef process(model, img):\n    # Normalize image to [0, 1]\n    img = (img / 255.0).astype(np.float32)\n\n    # Convert image to tensor and add batch dimension\n    img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n\n    # Forward pass through the model\n    with torch.no_grad():\n        sr = model(img_tensor).clamp(0, 1)\n\n    # Convert model output to numpy array and denormalize to [0, 255]\n    sr_img = sr.squeeze().permute(1, 2, 0).cpu().numpy()\n    return (sr_img * 255.0).round().astype(np.uint8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.418269Z","iopub.execute_input":"2025-04-07T11:30:31.418492Z","iopub.status.idle":"2025-04-07T11:30:31.431832Z","shell.execute_reply.started":"2025-04-07T11:30:31.418474Z","shell.execute_reply":"2025-04-07T11:30:31.431222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation Function","metadata":{}},{"cell_type":"code","source":"# Evaluate model using PSNR on validation set\ndef evaluate(model, val_low_dir, val_high_dir):\n    scores = []\n    model.eval()\n    for filename in os.listdir(val_low_dir):\n        low = cv2.imread(os.path.join(val_low_dir, filename))[:, :, ::-1]\n        high = cv2.imread(os.path.join(val_high_dir, filename))[:, :, ::-1]\n        output = process(model, low)\n        scores.append(psnr(high, output))\n\n    # Return average PSNR score\n    return np.mean(scores)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.432555Z","iopub.execute_input":"2025-04-07T11:30:31.432765Z","iopub.status.idle":"2025-04-07T11:30:31.447922Z","shell.execute_reply.started":"2025-04-07T11:30:31.432739Z","shell.execute_reply":"2025-04-07T11:30:31.447124Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference on Test Images","metadata":{}},{"cell_type":"code","source":"# Inference function for test images\ndef infer(model, test_dir, save_dir):\n    # Ensure output directory exists\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Set the model to evaluation mode \n    model.eval()\n\n    \n    for filename in os.listdir(test_dir):\n        img = cv2.imread(os.path.join(test_dir, filename))[:, :, ::-1]\n        sr_img = process(model, img)\n        cv2.imwrite(os.path.join(save_dir, filename), sr_img[:, :, ::-1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.448640Z","iopub.execute_input":"2025-04-07T11:30:31.448817Z","iopub.status.idle":"2025-04-07T11:30:31.460986Z","shell.execute_reply.started":"2025-04-07T11:30:31.448802Z","shell.execute_reply":"2025-04-07T11:30:31.460388Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Function (Fine-Tuning)","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, epochs=10, lr=1e-4):\n\n    # Set model to training mode\n    model.train()\n\n    # defining mean square error as the loss function\n    criterion = nn.MSELoss()\n\n    # use of adam optimizer\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # train for the specified num of epochs\n    for epoch in range(epochs):\n\n        # progress bar for tracking status\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n\n        # Iterate through each batch\n        for lr_img, hr_img in pbar:\n            \n            lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n\n            # clear gradiaent before bp\n            optimizer.zero_grad()\n\n            # forword pass\n            sr = model(lr_img)\n            loss = criterion(sr, hr_img)\n            loss.backward()\n\n            # update model parameters\n            optimizer.step()\n\n            # show current batch\n            pbar.set_postfix(loss=loss.item())\n\n        # clear cache memory to avoid mem. overflow\n        torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.461778Z","iopub.execute_input":"2025-04-07T11:30:31.462027Z","iopub.status.idle":"2025-04-07T11:30:31.474549Z","shell.execute_reply.started":"2025-04-07T11:30:31.462008Z","shell.execute_reply":"2025-04-07T11:30:31.473855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class Discriminator(nn.Module):\n#     def __init__(self):\n#         super(Discriminator, self).__init__()\n#         self.model = nn.Sequential(\n#             nn.Conv2d(3, 64, 3, stride=2, padding=1),     # üîÅ Changed from 1 to 3\n#             nn.LeakyReLU(0.2, inplace=True),\n\n#             nn.Conv2d(64, 128, 3, stride=2, padding=1),\n#             nn.BatchNorm2d(128),\n#             nn.LeakyReLU(0.2, inplace=True),\n\n#             nn.Conv2d(128, 256, 3, stride=2, padding=1),\n#             nn.BatchNorm2d(256),\n#             nn.LeakyReLU(0.2, inplace=True),\n\n#             nn.Conv2d(256, 512, 3, stride=2, padding=1),\n#             nn.BatchNorm2d(512),\n#             nn.LeakyReLU(0.2, inplace=True),\n\n#             nn.AdaptiveAvgPool2d((1, 1)),\n#             nn.Flatten(),\n#             nn.Linear(512, 1),\n#             nn.Sigmoid()\n#         )\n\n#     def forward(self, x):\n#         return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.475356Z","iopub.execute_input":"2025-04-07T11:30:31.475642Z","iopub.status.idle":"2025-04-07T11:30:31.492481Z","shell.execute_reply.started":"2025-04-07T11:30:31.475614Z","shell.execute_reply":"2025-04-07T11:30:31.491680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport gc\nfrom tqdm import tqdm\n\n# def train_with_gan(model, discriminator, train_loader, epochs=2, lr=1e-4, gan_weight=1e-3):\n#     model.train()\n#     discriminator.train()\n\n#     # Loss functions\n#     mse_loss = nn.MSELoss()\n#     gan_loss = nn.BCEWithLogitsLoss()\n\n#     # Optimizers\n#     optimizer_G = optim.Adam(model.parameters(), lr=lr)\n#     optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n\n#     for epoch in range(epochs):\n#         pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n#         for lr_img, hr_img in pbar:\n#             lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n\n#             valid = torch.ones((lr_img.size(0), 1), device=device)\n#             fake = torch.zeros((lr_img.size(0), 1), device=device)\n\n#             # ---- Train Generator ----\n#             optimizer_G.zero_grad()\n#             sr = model(lr_img)\n#             pred_fake = discriminator(sr)\n\n#             loss_mse = mse_loss(sr, hr_img)\n#             loss_gan = gan_loss(pred_fake, valid)\n#             loss_G = loss_mse + gan_weight * loss_gan\n#             loss_G.backward()\n#             optimizer_G.step()\n\n#             # ---- Train Discriminator ----\n#             optimizer_D.zero_grad()\n#             pred_real = discriminator(hr_img.detach())\n#             pred_fake = discriminator(sr.detach())\n#             loss_real = gan_loss(pred_real, valid)\n#             loss_fake = gan_loss(pred_fake, fake)\n#             loss_D = 0.5 * (loss_real + loss_fake)\n#             loss_D.backward()\n#             optimizer_D.step()\n\n        #     pbar.set_postfix(MSE=loss_mse.item(), GAN=loss_gan.item())\n\n        #     # Free memory\n        #     del sr, pred_fake, pred_real, loss_G, loss_D, loss_mse, loss_gan\n        #     torch.cuda.empty_cache()\n        #     gc.collect()\n\n        # torch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.493204Z","iopub.execute_input":"2025-04-07T11:30:31.493407Z","iopub.status.idle":"2025-04-07T11:30:31.505751Z","shell.execute_reply.started":"2025-04-07T11:30:31.493390Z","shell.execute_reply":"2025-04-07T11:30:31.505054Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Main Execution Block","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Load model\n    model = load_esrgan_model()\n    # discriminator = Discriminator().to(device)\n\n\n    # Prepare Dataset\n    train_dataset = PairedImageDataset(\n        '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/train',\n        '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/gt'\n        # transform=transform\n    )\n\n    # Use only half data for training\n    # half_size = len(train_dataset) // 2\n    # train_subset, _ = random_split(train_dataset, [half_size, len(train_dataset) - half_size])\n    # train_loader = DataLoader(train_subset, batch_size=1, shuffle=True)\n\n    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n\n    # Fine-tune the model\n    print(\"Starting fine-tuning...\")\n    train(model, train_loader, epochs=10, lr=1e-4)\n    # train_with_gan(model, train_loader, epochs=1, lr=1e-3)\n    # train_with_gan(model, discriminator, train_loader, epochs=2, lr=1e-4)\n\n    # # Evaluate after fine-tuning\n    # print(\"Evaluating on validation set...\")\n    # val_psnr = evaluate(model,\n    #     '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/val',\n    #     '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/gt'\n    # )\n    # print(f\"Validation PSNR: {val_psnr:.2f}\")\n\n    # Inference on test set\n    print(\"Running inference on test set...\")\n    infer(model, '/kaggle/input/dlp-jan-2025-nppe-3/archive/test', '/kaggle/working/esrgan_outputs')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T11:30:31.506395Z","iopub.execute_input":"2025-04-07T11:30:31.506644Z","iopub.status.idle":"2025-04-07T12:19:05.867022Z","shell.execute_reply.started":"2025-04-07T11:30:31.506618Z","shell.execute_reply":"2025-04-07T12:19:05.865877Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# infer(model, '/kaggle/input/dlp-jan-2025-nppe-3/archive/test', '/kaggle/working/esrgan_outputs')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T12:20:10.496829Z","iopub.execute_input":"2025-04-07T12:20:10.497188Z","iopub.status.idle":"2025-04-07T12:20:22.395371Z","shell.execute_reply.started":"2025-04-07T12:20:10.497159Z","shell.execute_reply":"2025-04-07T12:20:22.394620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\ndef images_to_csv(folder_path, output_csv):\n    data_rows = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L') \n            image_array = np.array(image).flatten()[::8]\n            # Replace 'test_' with 'gt_' in the ID\n            image_id = filename.split('.')[0].replace('test_', 'gt_')\n            data_rows.append([image_id, *image_array])\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n\nfolder_path = '/kaggle/working/esrgan_outputs'\noutput_csv = 'submission.csv'\nimages_to_csv(folder_path, output_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T12:20:28.262483Z","iopub.execute_input":"2025-04-07T12:20:28.262783Z","iopub.status.idle":"2025-04-07T12:21:13.228865Z","shell.execute_reply.started":"2025-04-07T12:20:28.262760Z","shell.execute_reply":"2025-04-07T12:21:13.228117Z"}},"outputs":[],"execution_count":null}]}