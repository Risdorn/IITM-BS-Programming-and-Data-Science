{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97753,"databundleVersionId":11639668,"sourceType":"competition"},{"sourceId":11294582,"sourceType":"datasetVersion","datasetId":7062308},{"sourceId":324329,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":273114,"modelId":294070}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\n\ndef load_images_from_dlp_competition(noisy_dir, gt_dir):\n    noisy_images = []\n    clean_images = []\n    image_ids = []\n\n    # Sort to ensure alignment\n    noisy_filenames = sorted(os.listdir(noisy_dir))\n    gt_filenames = sorted(os.listdir(gt_dir))\n\n    for noisy_name, gt_name in zip(noisy_filenames, gt_filenames):\n        noisy_path = os.path.join(noisy_dir, noisy_name)\n        gt_path = os.path.join(gt_dir, gt_name)\n\n        # Load both images\n        noisy_img = Image.open(noisy_path).convert('RGB')\n        gt_img = Image.open(gt_path).convert('RGB')\n\n        # Convert to NumPy arrays\n        noisy_array = np.array(noisy_img)\n        gt_array = np.array(gt_img)\n\n        noisy_images.append(noisy_array)\n        clean_images.append(gt_array)\n        image_ids.append(noisy_name)\n\n    return np.array(noisy_images), np.array(clean_images), image_ids\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###EDA\ntrain_noisy_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/train'\ntrain_gt_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/gt'\n\nval_noisy_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/val'   # path to noisy low-res images\nval_gt_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/gt'         # path to clean high-res ground truth images\n\nnoisy_imgs, clean_imgs, ids = load_images_from_dlp_competition(train_noisy_folder, train_gt_folder)\nval_noisy_imgs, val_clean_imgs, ids = load_images_from_dlp_competition(val_noisy_folder, val_gt_folder)\n\nprint(f\"Loaded train {len(noisy_imgs)} image pairs.\")\nprint(f\"Val Noisy image shape: {noisy_imgs[0].shape}, Ground truth shape: {clean_imgs[0].shape}\")\n\nprint(f\"Loaded Val {len(val_noisy_imgs)} image pairs.\")\nprint(f\"Val Noisy image shape: {val_noisy_imgs[0].shape}, Ground truth shape: {val_clean_imgs[0].shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_sample_pairs(noisy_imgs, clean_imgs, image_ids, n=3):\n    plt.figure(figsize=(12, 4 * n))\n    for i in range(n):\n        # Noisy\n        plt.subplot(n, 2, 2*i + 1)\n        plt.imshow(noisy_imgs[i])\n        plt.title(f\"Noisy Image: {image_ids[i]}\")\n        plt.axis('off')\n        \n        # Ground Truth\n        plt.subplot(n, 2, 2*i + 2)\n        plt.imshow(clean_imgs[i])\n        plt.title(\"Ground Truth\")\n        plt.axis('off')\n        \n    plt.tight_layout()\n    plt.show()\n\nplot_sample_pairs(noisy_imgs, clean_imgs, ids)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\ndef plot_intensity_comparison(noisy_img, clean_img):\n    noisy_gray = np.array(Image.fromarray(noisy_img).convert('L')).flatten()\n    clean_gray = np.array(Image.fromarray(clean_img).convert('L')).flatten()\n\n    plt.figure(figsize=(10, 4))\n    sns.histplot(noisy_gray, label='Noisy', color='orange', kde=True)\n    sns.histplot(clean_gray, label='Ground Truth', color='blue', kde=True)\n    plt.title(\"Pixel Intensity Distribution (Grayscale)\")\n    plt.xlabel(\"Pixel Value\")\n    plt.legend()\n    plt.show()\n\nplot_intensity_comparison(noisy_imgs[0], clean_imgs[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def summarize_images(imgs, label):\n    imgs_flat = imgs.astype(np.float32).reshape(len(imgs), -1)\n    print(f\"--- {label} Image Stats ---\")\n    print(\"Mean:\", np.mean(imgs_flat))\n    print(\"Std Dev:\", np.std(imgs_flat))\n    print(\"Min:\", np.min(imgs_flat))\n    print(\"Max:\", np.max(imgs_flat))\n    print()\n\nsummarize_images(noisy_imgs, \"Noisy\")\nsummarize_images(clean_imgs, \"Ground Truth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_noise_map(noisy, clean):\n    noisy_resized = np.array(Image.fromarray(noisy).resize(clean.shape[1::-1], Image.BICUBIC))\n    diff = np.abs(noisy_resized.astype(int) - clean.astype(int))\n\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 3, 1)\n    plt.imshow(noisy_resized)\n    plt.title(\"Upscaled Noisy\")\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(clean)\n    plt.title(\"Ground Truth\")\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(diff)\n    plt.title(\"Difference Map\")\n    plt.show()\n\nvisualize_noise_map(noisy_imgs[0], clean_imgs[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nimport cv2\n\ndef calculate_psnr(img1, img2):\n    mse = np.mean((img1.astype(np.float32) - img2.astype(np.float32)) ** 2)\n    if mse == 0:\n        return float('inf')\n    PIXEL_MAX = 255.0\n    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n\n# Example:\nnoisy_upscaled = np.array(Image.fromarray(noisy_imgs[0]).resize(clean_imgs[0].shape[1::-1], Image.BICUBIC))\npsnr_value = calculate_psnr(noisy_upscaled, clean_imgs[0])\nprint(f\"PSNR between upscaled noisy and ground truth: {psnr_value:.2f} dB\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_noisy= noisy_imgs\ntrain_gt =clean_imgs\n\nval_noisy= val_noisy_imgs\nval_gt= val_clean_imgs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor, Compose\n\ntransform = Compose([ToTensor()])\n\nclass DLPDataset(Dataset):\n    def __init__(self, noisy_imgs, clean_imgs):\n        self.noisy_imgs = noisy_imgs\n        self.clean_imgs = clean_imgs\n\n    def __len__(self):\n        return len(self.noisy_imgs)\n\n    def __getitem__(self, idx):\n        noisy = transform(Image.fromarray(self.noisy_imgs[idx])) * 255.0\n        clean = transform(Image.fromarray(self.clean_imgs[idx])) * 255.0\n        return noisy, clean\n\ntrain_dataset = DLPDataset(train_noisy, train_gt)\nval_dataset = DLPDataset(val_noisy, val_gt)\n\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nimport math\n\ndef calculate_batch_psnr(output, target):\n    mse = F.mse_loss(output, target, reduction='none')\n    mse = mse.view(mse.size(0), -1).mean(dim=1)\n    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n    return psnr.mean().item()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone --depth=1 https://github.com/sanghyun-son/EDSR-PyTorch.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Check if EDSR-PyTorch was cloned\nprint(\"EDSR-PyTorch\" in os.listdir())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change directory into the repo\nos.chdir(\"EDSR-PyTorch\")\n\n# List contents to verify\nprint(os.listdir())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append('./src')  # Not 'code', it's 'src'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.listdir('./src'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport os\n\n# Step 1: Prevent argparse from picking up unwanted notebook args\nsys.argv = ['']  # 🛑 Clear CLI args before importing\n\n# Step 2: Add src directory to path\nsys.path.append('./src')\n\n# Step 3: Import EDSR and args safely\nfrom model.edsr import EDSR\nfrom option import args  # No more SystemExit!\n\n# Step 4: Customize args\nargs.scale = [4]\nargs.n_resblocks = 8\nargs.n_feats = 64\nargs.rgb_range = 255\nargs.res_scale = 1\nargs.n_colors = 3\n\n# Step 5: Create the model\nmodel = EDSR(args).cuda()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.nn.utils import clip_grad_norm_\n\n# Setup\nmodel = EDSR(args).cuda()\ncriterion = nn.L1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscaler = torch.cuda.amp.GradScaler()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Halve LR every 5 epochs\n\nbest_psnr = 0\nsave_path = \"best_model.pth\"\n\ndef calculate_psnr(pred, target, max_val=255.0):\n    mse = nn.functional.mse_loss(pred, target)\n    psnr = 20 * torch.log10(max_val / torch.sqrt(mse + 1e-8))\n    return psnr.item()\n\n# Training Loop\nnum_epochs = 20\nmodel.train()\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    loop = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n\n    for noisy, clean in loop:\n        noisy = noisy.cuda()\n        clean = clean.cuda()\n\n        optimizer.zero_grad()\n        with torch.amp.autocast(\"cuda\"):  # AMP-enabled\n            output = model(noisy)\n\n            # Debug: check output range\n            if torch.any(torch.isnan(output)) or torch.any(torch.isinf(output)):\n                print(\"⚠️ NaN or Inf in model output!\")\n\n            # Optional: clamp output values\n            # output = torch.clamp(output, 0, 255)\n\n            loss = criterion(output, clean)\n\n        scaler.scale(loss).backward()\n        clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n\n    scheduler.step()\n    print(f\"[Epoch {epoch+1}] Training Loss: {total_loss / len(train_loader):.4f}\")\n\n    # Validation\n    model.eval()\n    val_psnr = 0\n    with torch.no_grad():\n        for noisy, clean in tqdm(val_loader, desc=\"Validating\"):\n            noisy = noisy.cuda()\n            clean = clean.cuda()\n            output = model(noisy)\n            val_psnr += calculate_psnr(output, clean)\n\n    val_psnr /= len(val_loader)\n    print(f\"[Epoch {epoch+1}] Validation PSNR: {val_psnr:.2f} dB\")\n\n    if val_psnr > best_psnr:\n        best_psnr = val_psnr\n        torch.save(model.state_dict(), save_path)\n        print(f\"✅ Saved new best model with PSNR: {best_psnr:.2f} dB\")\n\n    model.train()\n\n# Load best model\nmodel.load_state_dict(torch.load(save_path))\nprint(\"🔁 Loaded best model for inference.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the image\nimage_path = '/kaggle/input/dlp-jan-2025-nppe-3/archive/test/test_00001.png'\n\n# Open and check the image size\nwith Image.open(image_path) as img:\n    print(\"Image size:\", img.size)  # (width, height)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\n\ndef load_test_images(test_folder):\n    filenames = sorted(os.listdir(test_folder))\n    images = []\n\n    for fname in filenames:\n        img_path = os.path.join(test_folder, fname)\n        img = Image.open(img_path).convert('RGB')\n        images.append(np.array(img))\n\n    return images, filenames\n\ntest_folder = \"/kaggle/input/dlp-jan-2025-nppe-3/archive/test\"\ntest_images, test_filenames = load_test_images(test_folder)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor\n\nclass TestDataset(Dataset):\n    def __init__(self, images):\n        self.images = images\n        self.transform = ToTensor()\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.transform(Image.fromarray(self.images[idx])) * 255.0\n        return img\n\ntest_dataset = TestDataset(test_images)\ntest_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms import ToPILImage\nimport torch\n\nmodel.eval()\nos.makedirs(\"outputs\", exist_ok=True)\nto_pil = ToPILImage()\n\nwith torch.no_grad():\n    idx = 0\n    for batch in test_loader:\n        batch = batch.cuda()\n        preds = model(batch).clamp(0, 255)\n\n        for i in range(preds.size(0)):\n            img = to_pil(preds[i].cpu() / 255.0)  # Scale [0,255] → [0,1] for PIL\n            out_name = test_filenames[idx].replace(\".jpg\", \".png\")  # match your original\n            img.save(f\"outputs/{out_name}\")\n            idx += 1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def images_to_csv(folder_path, output_csv):\n    data_rows = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L') \n            image_array = np.array(image).flatten()[::8]\n            # Replace 'test_' with 'gt_' in the ID\n            image_id = filename.split('.')[0].replace('test_', 'gt_')\n            data_rows.append([image_id, *image_array])\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folder_path = 'outputs'\noutput_csv = '/kaggle/working/submission.csv'\nimages_to_csv(folder_path, output_csv)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load submission.csv\nsubmission_df = pd.read_csv('/kaggle/working/submission.csv')\n\n# Show basic info\nprint(submission_df.info())\n\n# Show first few rows\nsubmission_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load submission CSV\ndf = submission_df\n\n# Basic Info\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns[:10], \"...\")  # Show some column names\nprint(\"Sample IDs:\", df['ID'].head().tolist())\n\n# Check pixel value range\npixel_columns = df.columns[1:]\nall_pixels = df[pixel_columns].values.flatten()\nprint(\"Pixel stats → Min:\", np.min(all_pixels), \"Max:\", np.max(all_pixels), \"Mean:\", np.mean(all_pixels))\n\n# Plot a few sample images\ndef plot_sample_images(df, num_images=4):\n    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n    for i in range(num_images):\n        img_data = df.iloc[i, 1:].values.astype(np.uint8)\n        # Reshape to known size: (640, 1024) → (2560, 4096) before downsampling ::8 → back to 640x1024 // 8 = 81920\n        img = img_data.reshape(256, 320)  # 256*320 = 81920\n        axs[i].imshow(img, cmap='gray')\n        axs[i].set_title(df.iloc[i, 0])\n        axs[i].axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nplot_sample_images(df)\n\n# Histogram of pixel intensities\nplt.figure(figsize=(8, 4))\nplt.hist(all_pixels, bins=50, color='steelblue', edgecolor='black')\nplt.title(\"Pixel Intensity Distribution\")\nplt.xlabel(\"Pixel Value\")\nplt.ylabel(\"Frequency\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###using esrgan","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the image\nimage_path = '/kaggle/working/EDSR-PyTorch/outputs/test_00001.png'\n\n# Open and check the image size\nwith Image.open(image_path) as img:\n    print(\"Image size:\", img.size)  # (width, height)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf Real-ESRGAN\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/xinntao/Real-ESRGAN\n%cd Real-ESRGAN\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install basicsr facexlib gfpgan\n!pip install -r requirements.txt\n!python setup.py develop\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pwd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls scripts\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p experiments/pretrained_models\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://huggingface.co/lllyasviel/Annotators/resolve/main/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade torchvision\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python inference_realesrgan.py \\\n-n RealESRGAN_x4plus \\\n-i /kaggle/working/EDSR-PyTorch/outputs\\\n--face_enhance\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!find . -type f -name \"*.png\"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the image\nimage_path = './results/test_00020_out.png'\n\n# Open and check the image size\nwith Image.open(image_path) as img:\n    print(\"Image size:\", img.size)  # (width, height)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\ndef images_to_csv(folder_path, output_csv):\n    data_rows = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L') \n            image_array = np.array(image).flatten()[::8]\n            # Replace 'test_' with 'gt_' in the ID\n            image_id = filename.split('.')[0].replace('test_', 'gt_')\n            data_rows.append([image_id, *image_array])\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\ndef images_to_csv1(folder_path, output_csv):\n    data_rows = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L').resize((1024, 640))\n            image_array = np.array(image).flatten()[::8]\n            \n            # Extract ID from something like 'test_00043_out.png'\n            base = os.path.splitext(filename)[0]  # test_00043_out\n            parts = base.split('_')               # ['test', '00043', 'out']\n            if len(parts) >= 2:\n                image_id = f\"gt_{parts[1]}\"       # gt_00043\n            else:\n                image_id = base                   # fallback if unexpected format\n            \n            data_rows.append([image_id, *image_array])\n    \n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n\n# Call the function\nfolder_path = './results/'\noutput_csv = '/kaggle/working/submission_1.csv'\nimages_to_csv1(folder_path, output_csv)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load submission.csv\nsubmission_df = pd.read_csv('/kaggle/working/submission_1.csv')\n\n# Show basic info\nprint(submission_df.info())\n\n# Show first few rows\nsubmission_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load submission CSV\ndf = submission_df\n\n# Basic Info\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns[:10], \"...\")  # Show some column names\nprint(\"Sample IDs:\", df['ID'].head().tolist())\n\n# Check pixel value range\npixel_columns = df.columns[1:]\nall_pixels = df[pixel_columns].values.flatten()\nprint(\"Pixel stats → Min:\", np.min(all_pixels), \"Max:\", np.max(all_pixels), \"Mean:\", np.mean(all_pixels))\n\n# Plot a few sample images\ndef plot_sample_images(df, num_images=4):\n    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n    for i in range(num_images):\n        img_data = df.iloc[i, 1:].values.astype(np.uint8)\n        # Reshape to known size: (640, 1024) → (2560, 4096) before downsampling ::8 → back to 640x1024 // 8 = 81920\n        img = img_data.reshape(256, 320)  # 256*320 = 81920\n        axs[i].imshow(img, cmap='gray')\n        axs[i].set_title(df.iloc[i, 0])\n        axs[i].axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nplot_sample_images(df)\n\n# Histogram of pixel intensities\nplt.figure(figsize=(8, 4))\nplt.hist(all_pixels, bins=50, color='steelblue', edgecolor='black')\nplt.title(\"Pixel Intensity Distribution\")\nplt.xlabel(\"Pixel Value\")\nplt.ylabel(\"Frequency\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###Using swinIR","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/JingyunLiang/SwinIR.git\n%cd SwinIR","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p experiments/pretrained_models\n\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/004_grayDN_DFWB_s128w8_SwinIR-M_noise15.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/004_grayDN_DFWB_s128w8_SwinIR-M_noise25.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/004_grayDN_DFWB_s128w8_SwinIR-M_noise50.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise15.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise25.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise50.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg10.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg20.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg30.pth -P experiments/pretrained_models\n!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg40.pth -P experiments/pretrained_models\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls experiments/pretrained_models","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms import Resize, Compose, Grayscale, ToTensor\nfrom torch.utils.data import Dataset, DataLoader\n\ntransform = Compose([\n    Grayscale(num_output_channels=1),\n    Resize((128, 128)),\n    ToTensor()\n])\n\nclass DLPDataset1(Dataset):\n    def __init__(self, noisy_imgs, clean_imgs):\n        self.noisy_imgs = noisy_imgs\n        self.clean_imgs = clean_imgs\n\n    def __len__(self):\n        return len(self.noisy_imgs)\n\n    def __getitem__(self, idx):\n        noisy = transform(Image.fromarray(self.noisy_imgs[idx])) * 255.0\n        clean = transform(Image.fromarray(self.clean_imgs[idx])) * 255.0\n        return noisy, clean\n\ntrain_dataset = DLPDataset1(train_noisy, train_gt)\nval_dataset = DLPDataset1(val_noisy, val_gt)\n\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install basicsr","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from basicsr.archs.swinir_arch import SwinIR\nimport torch\nimport torch.nn as nn\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = SwinIR(\n    upscale=1,\n    in_chans=1,\n    img_size=128,  # adjust if your patch size is different\n    window_size=8,\n    img_range=255.0,\n    depths=[6, 6, 6, 6, 6, 6],\n    embed_dim=180,\n    num_heads=[6, 6, 6, 6, 6, 6],\n    mlp_ratio=2,\n    upsampler='',  # for denoising\n    resi_connection='1conv'\n).to(device)\n\ncriterion = nn.L1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nnum_epochs = 10","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nfrom skimage.metrics import peak_signal_noise_ratio as compare_psnr\nfrom skimage.metrics import structural_similarity as compare_ssim\n\ndef train_one_epoch(model, dataloader, criterion, optimizer):\n    model.train()\n    total_loss = 0.0\n    for noisy, clean in tqdm(dataloader, desc=\"Training\"):\n        noisy, clean = noisy.to(device), clean.to(device)\n        optimizer.zero_grad()\n        output = model(noisy)\n        loss = criterion(output, clean)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n\ndef validate(model, dataloader, criterion):\n    model.eval()\n    total_loss = 0.0\n    total_psnr = 0.0\n    total_ssim = 0.0\n    torch.cuda.empty_cache()  # ← clear unused memory\n    \n    with torch.no_grad():\n        for noisy, clean in tqdm(dataloader, desc=\"Validating\"):\n            noisy, clean = noisy.to(device), clean.to(device)\n            output = model(noisy)\n\n            loss = criterion(output, clean)\n            total_loss += loss.item()\n\n            output_np = output.cpu().numpy()\n            clean_np = clean.cpu().numpy()\n\n            # Loop over batch\n            for i in range(output_np.shape[0]):\n                out_img = np.squeeze(output_np[i])\n                gt_img = np.squeeze(clean_np[i])\n\n                psnr = compare_psnr(gt_img, out_img, data_range=255.0)\n                ssim = compare_ssim(gt_img, out_img, data_range=255.0)\n\n                total_psnr += psnr\n                total_ssim += ssim\n\n    n = len(dataloader.dataset)\n    return (\n        total_loss / len(dataloader),\n        total_psnr / n,\n        total_ssim / n\n    )\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_psnr = 0.0\n\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    \n    train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n    val_loss, val_psnr, val_ssim = validate(model, val_loader, criterion)\n\n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | PSNR: {val_psnr:.2f} | SSIM: {val_ssim:.4f}\")\n    \n    if val_psnr > best_psnr:\n        best_psnr = val_psnr\n        torch.save(model.state_dict(), f\"best_swinir_psnr_{best_psnr:.2f}.pth\")\n        print(f\"✅ Saved new best model at Epoch {epoch+1} with PSNR: {val_psnr:.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###inference\nfrom torchvision.transforms import Resize, Compose, Grayscale, ToTensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\n\ntest_transform = Compose([\n    Grayscale(num_output_channels=1),\n    Resize((1024, 640)),\n    ToTensor()\n])\n\nclass TestDataset(Dataset):\n    def __init__(self, noisy_imgs):\n        self.noisy_imgs = noisy_imgs\n\n    def __len__(self):\n        return len(self.noisy_imgs)\n\n    def __getitem__(self, idx):\n        noisy = test_transform(Image.fromarray(self.noisy_imgs[idx])) * 255.0\n        return noisy\n\ntest_images, test_filenames = load_test_images(test_folder)\n\ntest_dataset = TestDataset(test_images)  # not test_noisy\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms import ToPILImage\nimport torch\n\n# --- Load best model ---\nmodel.load_state_dict(torch.load(\"/kaggle/working/SwinIR/best_swinir_psnr_43.99.pth\"))\nmodel.eval()\n\n# --- Inference & Save ---\nos.makedirs(\"outputs1\", exist_ok=True)\nto_pil = ToPILImage()\n\nwith torch.no_grad():\n    for idx, batch in enumerate(test_loader):\n        batch = batch.cuda()\n        preds = model(batch).clamp(0, 255)\n\n        # Convert tensor to image and save\n        img = to_pil(preds[0].cpu() / 255.0)  # Normalize for PIL\n        out_name = test_filenames[idx].rsplit(\".\", 1)[0] + \".png\"\n        img.save(f\"outputs1/{out_name}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the image\nimage_path = '/kaggle/working/SwinIR/outputs1/test_00001.png'\n\n# Open and check the image size\nwith Image.open(image_path) as img:\n    print(\"Image size:\", img.size)  # (width, height)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\ndef images_to_csv3(folder_path, output_csv):\n    data_rows = []\n    for filename in os.listdir(folder_path):\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L').resize((1024, 640))\n            image_array = np.array(image).flatten()[::8]  # downsample\n\n            # Extract ID from something like 'test_00043_SwinIR.png'\n            base = os.path.splitext(filename)[0]      # test_00043_SwinIR\n            parts = base.split('_')                   # ['test', '00043', 'SwinIR']\n            if len(parts) >= 2 and parts[1].isdigit():\n                image_id = f\"gt_{parts[1]}\"           # gt_00043\n            else:\n                image_id = base\n\n            data_rows.append([image_id, *image_array])\n    \n    if not data_rows:\n        print(\"No valid images found.\")\n        return\n\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n\n# Call the function\nfolder_path = '/kaggle/working/SwinIR/outputs1'\noutput_csv = '/kaggle/working/submission_3.csv'\nimages_to_csv3(folder_path, output_csv)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load submission.csv\nsubmission_df = pd.read_csv('/kaggle/working/submission_3.csv')\n\n# Show basic info\nprint(submission_df.info())\n\n# Show first few rows\nsubmission_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('/kaggle/working/submission_3.csv')\nimport zipfile\n\nwith zipfile.ZipFile(\"/kaggle/working/submission.zip\", 'w') as zipf:\n    zipf.write(\"/kaggle/working/submission_3.csv\", arcname=\"submission_3.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load submission CSV\ndf = submission_df\n\n# Basic Info\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns[:10], \"...\")  # Show some column names\nprint(\"Sample IDs:\", df['ID'].head().tolist())\n\n# Check pixel value range\npixel_columns = df.columns[1:]\nall_pixels = df[pixel_columns].values.flatten()\nprint(\"Pixel stats → Min:\", np.min(all_pixels), \"Max:\", np.max(all_pixels), \"Mean:\", np.mean(all_pixels))\n\n# Plot a few sample images\ndef plot_sample_images(df, num_images=4):\n    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n    for i in range(num_images):\n        img_data = df.iloc[i, 1:].values.astype(np.uint8)\n        # Reshape to known size: (640, 1024) → (2560, 4096) before downsampling ::8 → back to 640x1024 // 8 = 81920\n        img = img_data.reshape(256, 320)  # 256*320 = 81920\n        axs[i].imshow(img, cmap='gray')\n        axs[i].set_title(df.iloc[i, 0])\n        axs[i].axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\nplot_sample_images(df)\n\n# Histogram of pixel intensities\nplt.figure(figsize=(8, 4))\nplt.hist(all_pixels, bins=50, color='steelblue', edgecolor='black')\nplt.title(\"Pixel Intensity Distribution\")\nplt.xlabel(\"Pixel Value\")\nplt.ylabel(\"Frequency\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}