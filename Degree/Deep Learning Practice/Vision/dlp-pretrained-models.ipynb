{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import vgg16, resnet18\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-09T06:28:24.455668Z","iopub.execute_input":"2024-09-09T06:28:24.456292Z","iopub.status.idle":"2024-09-09T06:28:29.222701Z","shell.execute_reply.started":"2024-09-09T06:28:24.456252Z","shell.execute_reply":"2024-09-09T06:28:29.221654Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:29.224940Z","iopub.execute_input":"2024-09-09T06:28:29.225341Z","iopub.status.idle":"2024-09-09T06:28:29.257359Z","shell.execute_reply.started":"2024-09-09T06:28:29.225307Z","shell.execute_reply":"2024-09-09T06:28:29.256409Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define the transformations\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:29.258910Z","iopub.execute_input":"2024-09-09T06:28:29.259329Z","iopub.status.idle":"2024-09-09T06:28:29.275285Z","shell.execute_reply.started":"2024-09-09T06:28:29.259277Z","shell.execute_reply":"2024-09-09T06:28:29.274450Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/imagenetmini-1000/imagenet-mini'","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:29.277667Z","iopub.execute_input":"2024-09-09T06:28:29.278445Z","iopub.status.idle":"2024-09-09T06:28:29.284704Z","shell.execute_reply.started":"2024-09-09T06:28:29.278396Z","shell.execute_reply":"2024-09-09T06:28:29.283848Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load the ImageNet validation dataset\nval_dataset = ImageFolder(root=os.path.join(dataset_path, 'val'), transform=transform)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:29.285713Z","iopub.execute_input":"2024-09-09T06:28:29.286016Z","iopub.status.idle":"2024-09-09T06:28:37.549342Z","shell.execute_reply.started":"2024-09-09T06:28:29.285985Z","shell.execute_reply":"2024-09-09T06:28:37.548419Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate the model\ndef evaluate_model(model, data_loader, device='cuda'):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return correct / total","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:37.551022Z","iopub.execute_input":"2024-09-09T06:28:37.551669Z","iopub.status.idle":"2024-09-09T06:28:37.559317Z","shell.execute_reply.started":"2024-09-09T06:28:37.551620Z","shell.execute_reply":"2024-09-09T06:28:37.558265Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"vgg_model = vgg16(pretrained=True).to(device)\nvgg_model","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:37.560867Z","iopub.execute_input":"2024-09-09T06:28:37.561237Z","iopub.status.idle":"2024-09-09T06:28:42.017868Z","shell.execute_reply.started":"2024-09-09T06:28:37.561193Z","shell.execute_reply":"2024-09-09T06:28:42.016730Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 223MB/s] \n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate VGG16\nvgg_accuracy = evaluate_model(vgg_model, val_loader)\nprint(f'VGG16 Accuracy on ImageNet: {vgg_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:28:55.279673Z","iopub.execute_input":"2024-09-09T06:28:55.280082Z","iopub.status.idle":"2024-09-09T06:30:02.462228Z","shell.execute_reply.started":"2024-09-09T06:28:55.280046Z","shell.execute_reply":"2024-09-09T06:30:02.461316Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"VGG16 Accuracy on ImageNet: 70.41%\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet_model = resnet18(pretrained=True).to(device)\nresnet_model","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:30:13.143727Z","iopub.execute_input":"2024-09-09T06:30:13.144135Z","iopub.status.idle":"2024-09-09T06:30:13.642964Z","shell.execute_reply.started":"2024-09-09T06:30:13.144096Z","shell.execute_reply":"2024-09-09T06:30:13.641952Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 230MB/s]\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate ResNet18\nresnet_accuracy = evaluate_model(resnet_model, val_loader)\nprint(f'ResNet18 Accuracy on ImageNet: {resnet_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:30:18.127293Z","iopub.execute_input":"2024-09-09T06:30:18.128124Z","iopub.status.idle":"2024-09-09T06:30:51.282494Z","shell.execute_reply.started":"2024-09-09T06:30:18.128066Z","shell.execute_reply":"2024-09-09T06:30:51.281542Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"ResNet18 Accuracy on ImageNet: 69.97%\n","output_type":"stream"}]}]}