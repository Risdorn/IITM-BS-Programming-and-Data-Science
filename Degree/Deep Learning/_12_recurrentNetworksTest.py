from _06_layers import rnnLayer
import numpy as np

parameters = np.load('Degree/Deep Learning/parameters_rnn.npz')

# This is the assignment question
# Generate the sequence 'learn' given the initial state 'l'
# The sequence is generated by the RNN layer
initialState = np.array([1, 0, 0, 0, 0]) # Represents the letter 'l'
initialState = initialState.reshape(5, 1)
# Represents the letters 'e', 'a', 'r', 'n', 'end'
words = {0: 'l', 1: 'e', 2: 'a', 3: 'r', 4: 'n', 5: 'end'}
x = [np.array([1, 0, 0, 0, 0]), np.array([0, 1, 0, 0, 0]), np.array([0, 0, 1, 0, 0]), np.array([0, 0, 0, 1, 0]), np.array([0, 0, 0, 0, 1])]
y = [np.array([0, 1, 0, 0, 0]), np.array([0, 0, 1, 0, 0]), np.array([0, 0, 0, 1, 0]), np.array([0, 0, 0, 0, 1]), np.array([0, 0, 0, 0, 0])]
for i in range(5):
    y[i] = y[i].reshape(5, 1)
    x[i] = x[i].reshape(5, 1)
input_size = 5
hidden_size = 5
output_size = 5
rnnModel = rnnLayer(input_size, hidden_size, output_size, random_seed=0)
rnnModel.input_weights = parameters.get('U')
rnnModel.input_bias = np.zeros((hidden_size, 1))
rnnModel.hidden_weights = parameters.get('W')
rnnModel.output_weights = parameters.get('V')
rnnModel.output_bias = np.zeros((output_size, 1))

y_hat = rnnModel.forward_constant(x, 5) # 5 time steps, to generate e, a, r, n
loss = 0
for i in range(4): # Last output is not considered, as there is no target for it
    j = np.argmax(y[i])
    print("Loss at time step", i+1, ":", -np.log(y_hat[i][j]))
    loss += -np.log(y_hat[i][j])
print('Initial Loss:', loss)

output_grads = []
for i in range(5):
    #print(y_hat[i].T[0], y[i])
    #print("Gradient at time step", i+1, ":", y_hat[i].T[0] - y[i])
    output_grads.append(y_hat[i] - y[i])

rnnModel.backward(output_grads) # Time steps are defined by the length of inputs
max_pos = [0,0]
for i in range(5):
    for j in range(5):
        if rnnModel.dL_dW[i][j] > rnnModel.dL_dW[max_pos[0]][max_pos[1]]:
            max_pos = [i, j]
print("Max element at position", max_pos, ":", rnnModel.dL_dW[max_pos[0]][max_pos[1]])
print("Sum of elements in dL_dW: ", np.sum(rnnModel.dL_dW))

rnnModel.update(1) # Update the weights with learning rate 1
# bias will also update, so we need to reset it
rnnModel.input_bias = np.zeros((hidden_size, 1))
rnnModel.output_bias = np.zeros((output_size, 1))

# running in auto mode for 5 time steps
y_hat = rnnModel.forward(initialState, 5)
print("Predicted sequence: ", end='')
for i in range(5):
    j = np.argmax(y_hat[i])
    print(words[j], end='')
